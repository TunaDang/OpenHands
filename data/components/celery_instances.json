[
    {
        "repo": "celery/celery",
        "pull_number": 8806,
        "instance_id": "celery__celery-8806",
        "issue_numbers": [
            "2907"
        ],
        "base_commit": "8f389997887232500d4aa1a2b0ae0c7320c4c84a",
        "patch": "diff --git a/CONTRIBUTORS.txt b/CONTRIBUTORS.txt\nindex e0a8394bc6f..6159effcc3a 100644\n--- a/CONTRIBUTORS.txt\n+++ b/CONTRIBUTORS.txt\n@@ -295,4 +295,5 @@ JoonHwan Kim, 2022/08/01\n Kaustav Banerjee, 2022/11/10\n Austin Snoeyink 2022/12/06\n Jeremy Z. Othieno 2023/07/27\n-Tomer Nosrati, 2022/17/07\n\\ No newline at end of file\n+Tomer Nosrati, 2022/17/07\n+Andy Zickler, 2024/01/18\n\\ No newline at end of file\ndiff --git a/celery/beat.py b/celery/beat.py\nindex 76e44721e14..9656493ecbe 100644\n--- a/celery/beat.py\n+++ b/celery/beat.py\n@@ -568,11 +568,11 @@ def _create_schedule(self):\n         for _ in (1, 2):\n             try:\n                 self._store['entries']\n-            except KeyError:\n+            except (KeyError, UnicodeDecodeError, TypeError):\n                 # new schedule db\n                 try:\n                     self._store['entries'] = {}\n-                except KeyError as exc:\n+                except (KeyError, UnicodeDecodeError, TypeError) as exc:\n                     self._store = self._destroy_open_corrupted_schedule(exc)\n                     continue\n             else:\n",
        "test_patch": "diff --git a/t/unit/app/test_beat.py b/t/unit/app/test_beat.py\nindex fa163bb931e..a95e8e41409 100644\n--- a/t/unit/app/test_beat.py\n+++ b/t/unit/app/test_beat.py\n@@ -2,7 +2,7 @@\n import sys\n from datetime import datetime, timedelta, timezone\n from pickle import dumps, loads\n-from unittest.mock import Mock, call, patch\n+from unittest.mock import MagicMock, Mock, call, patch\n \n import pytest\n \n@@ -669,6 +669,38 @@ def test_remove_db(self, remove):\n         with pytest.raises(OSError):\n             s._remove_db()\n \n+    def test_create_schedule_corrupted(self):\n+        \"\"\"\n+        Test that any decoding errors that might happen when opening beat-schedule.db are caught\n+        \"\"\"\n+        s = create_persistent_scheduler()[0](app=self.app,\n+                                             schedule_filename='schedule')\n+        s._store = MagicMock()\n+        s._destroy_open_corrupted_schedule = Mock()\n+        s._destroy_open_corrupted_schedule.return_value = MagicMock()\n+\n+        # self._store['entries'] will throw a KeyError\n+        s._store.__getitem__.side_effect = KeyError()\n+        # then, when _create_schedule tries to reset _store['entries'], throw another error\n+        expected_error = UnicodeDecodeError(\"ascii\", b\"ordinal not in range(128)\", 0, 0, \"\")\n+        s._store.__setitem__.side_effect = expected_error\n+\n+        s._create_schedule()\n+        s._destroy_open_corrupted_schedule.assert_called_with(expected_error)\n+\n+    def test_create_schedule_missing_entries(self):\n+        \"\"\"\n+        Test that if _create_schedule can't find the key \"entries\" in _store it will recreate it\n+        \"\"\"\n+        s = create_persistent_scheduler()[0](app=self.app, schedule_filename=\"schedule\")\n+        s._store = MagicMock()\n+\n+        # self._store['entries'] will throw a KeyError\n+        s._store.__getitem__.side_effect = TypeError()\n+\n+        s._create_schedule()\n+        s._store.__setitem__.assert_called_with(\"entries\", {})\n+\n     def test_setup_schedule(self):\n         s = create_persistent_scheduler()[0](app=self.app,\n                                              schedule_filename='schedule')\n",
        "problem_statement": "Celery beat UnicodeDecodeError (Python 3.4) issue\nI am using Python 3.4 with Celery 3.1.19\n\nRunning without beat it works properly:\n\n```\ncelery worker --app worker --config=celeryconfig --loglevel=info\n```\n\nBut with celery beat:\n\n```\ncelery worker --app worker -B --config=celeryconfig --loglevel=info\n```\n\nI got this exception:\n\n```\nTraceback (most recent call last):\n  File \"/env/lib/python3.4/site-packages/kombu/utils/__init__.py\", line 320, in __get__\n    return obj.__dict__[self.__name__]\nKeyError: 'scheduler'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/shelve.py\", line 111, in __getitem__\n    value = self.cache[key]\nKeyError: 'entries'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/env/lib/python3.4/site-packages/billiard/process.py\", line 292, in _bootstrap\n    self.run()\n  File \"/env/lib/python3.4/site-packages/celery/beat.py\", line 530, in run\n    self.service.start(embedded_process=True)\n  File \"/env/lib/python3.4/site-packages/celery/beat.py\", line 454, in start\n    humanize_seconds(self.scheduler.max_interval))\n  File \"/env/lib/python3.4/site-packages/kombu/utils/__init__.py\", line 322, in __get__\n    value = obj.__dict__[self.__name__] = self.__get(obj)\n  File \"/env/lib/python3.4/site-packages/celery/beat.py\", line 494, in scheduler\n    return self.get_scheduler()\n  File \"/env/lib/python3.4/site-packages/celery/beat.py\", line 489, in get_scheduler\n    lazy=lazy)\n  File \"/env/lib/python3.4/site-packages/celery/utils/imports.py\", line 53, in instantiate\n    return symbol_by_name(name)(*args, **kwargs)\n  File \"/env/lib/python3.4/site-packages/celery/beat.py\", line 358, in __init__\n    Scheduler.__init__(self, *args, **kwargs)\n  File \"/env/lib/python3.4/site-packages/celery/beat.py\", line 185, in __init__\n    self.setup_schedule()\n  File \"/env/lib/python3.4/site-packages/celery/beat.py\", line 377, in setup_schedule\n    self._store['entries']\n  File \"/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/shelve.py\", line 114, in __getitem__\n    value = Unpickler(f).load()\nUnicodeDecodeError: 'ascii' codec can't decode byte 0xdf in position 1: ordinal not in range(128)\n```\n\nAny ideas? Thanks in advance\n\n",
        "hints_text": "It works for me here, maybe you could try removing the celerybeat-schedule file?\n\nIt worked! thanks! I removed the `celerybeat-schedule.db` file in the current directory.\n\nMe too, thaks @ask ! Just so you know I've migrated from `Python 2.7.12` to `Python 3.5.3` and it started happening.\nWorked for me also, what I did is rename the file to \"celerybeat-schedule.db.backup\"\nin dicrectory Delete (rm) celerybeat-schedule.db and celerybeat-schedule like this \r\n\r\n```\r\ncd project-directory\r\nrm celerybeat-schedule.db celerybeat-schedule\r\n```",
        "created_at": "2024-01-19T00:56:19Z",
        "version": "5.4",
        "PASS_TO_PASS": [],
        "FAIL_TO_PASS": [
            "t/unit/app/test_beat.py"
        ]
    },
    {
        "repo": "celery/celery",
        "pull_number": 8702,
        "instance_id": "celery__celery-8702",
        "issue_numbers": [
            "8678"
        ],
        "base_commit": "17631f7eda712b688294ecb8fa53e4769fe2b1f9",
        "patch": "diff --git a/celery/canvas.py b/celery/canvas.py\nindex a4007f0a27f..a32d3eea7e7 100644\n--- a/celery/canvas.py\n+++ b/celery/canvas.py\n@@ -2271,6 +2271,8 @@ def link_error(self, errback):\n             ``False`` (the current default), then the error callback will only be\n             applied to the body.\n         \"\"\"\n+        errback = maybe_signature(errback)\n+\n         if self.app.conf.task_allow_error_cb_on_chord_header:\n             for task in maybe_list(self.tasks) or []:\n                 task.link_error(errback.clone(immutable=True))\n",
        "test_patch": "diff --git a/t/unit/tasks/test_canvas.py b/t/unit/tasks/test_canvas.py\nindex 2c3f4f12f3e..53dc52e5cbb 100644\n--- a/t/unit/tasks/test_canvas.py\n+++ b/t/unit/tasks/test_canvas.py\n@@ -1688,6 +1688,14 @@ def test_flag_allow_error_cb_on_chord_header_various_header_types(self):\n             errback = c.link_error(sig)\n             assert errback == sig\n \n+    @pytest.mark.usefixtures('depends_on_current_app')\n+    def test_flag_allow_error_cb_on_chord_header_with_dict_callback(self):\n+        self.app.conf.task_allow_error_cb_on_chord_header = True\n+        c = chord(group(signature('th1'), signature('th2')), signature('tbody'))\n+        errback_dict = dict(signature('tcb'))\n+        errback = c.link_error(errback_dict)\n+        assert errback == errback_dict\n+\n     def test_chord__or__group_of_single_task(self):\n         \"\"\" Test chaining a chord to a group of a single task. \"\"\"\n         c = chord([signature('header')], signature('body'))\n",
        "problem_statement": "task with an errback throws `AttributeError` when replaced with a chord, when `task_allow_error_cb_on_chord_header` is set\n<!--\r\nPlease fill this template entirely and do not erase parts of it.\r\nWe reserve the right to close without a response\r\nbug reports which are incomplete.\r\n-->\r\n# Checklist\r\n<!--\r\nTo check an item on the list replace [ ] with [x].\r\n-->\r\n- [x] I have verified that the issue exists against the `main` branch of Celery.\r\n- [ ] This has already been asked to the [discussions forum](https://github.com/celery/celery/discussions) first.\r\n- [x] I have read the relevant section in the\r\n  [contribution guide](https://docs.celeryq.dev/en/main/contributing.html#other-bugs)\r\n  on reporting bugs.\r\n- [x] I have checked the [issues list](https://github.com/celery/celery/issues?q=is%3Aissue+label%3A%22Issue+Type%3A+Bug+Report%22+-label%3A%22Category%3A+Documentation%22)\r\n  for similar or identical bug reports.\r\n- [x] I have checked the [pull requests list](https://github.com/celery/celery/pulls?q=is%3Apr+label%3A%22PR+Type%3A+Bugfix%22+-label%3A%22Category%3A+Documentation%22)\r\n  for existing proposed fixes.\r\n- [x] I have checked the [commit log](https://github.com/celery/celery/commits/main)\r\n  to find out if the bug was already fixed in the main branch.\r\n- [x] I have included all related issues and possible duplicate issues\r\n  in this issue (If there are none, check this box anyway).\r\n\r\n## Mandatory Debugging Information\r\n\r\n- [x] I have included the output of ``celery -A proj report`` in the issue.\r\n    (if you are not able to do this, then at least specify the Celery\r\n     version affected).\r\n- [x] I have verified that the issue exists against the `main` branch of Celery.\r\n- [x] I have included the contents of ``pip freeze`` in the issue.\r\n- [x] I have included all the versions of all the external dependencies required\r\n  to reproduce this bug.\r\n\r\n## Optional Debugging Information\r\n<!--\r\nTry some of the below if you think they are relevant.\r\nIt will help us figure out the scope of the bug and how many users it affects.\r\n-->\r\n- [ ] I have tried reproducing the issue on more than one Python version\r\n  and/or implementation.\r\n- [ ] I have tried reproducing the issue on more than one message broker and/or\r\n  result backend.\r\n- [ ] I have tried reproducing the issue on more than one version of the message\r\n  broker and/or result backend.\r\n- [ ] I have tried reproducing the issue on more than one operating system.\r\n- [x] I have tried reproducing the issue on more than one workers pool.\r\n- [ ] I have tried reproducing the issue with autoscaling, retries,\r\n  ETA/Countdown & rate limits disabled.\r\n- [x] I have tried reproducing the issue after downgrading\r\n  and/or upgrading Celery and its dependencies.\r\n\r\n## Related Issues and Possible Duplicates\r\n<!--\r\nPlease make sure to search and mention any related issues\r\nor possible duplicates to this issue as requested by the checklist above.\r\n\r\nThis may or may not include issues in other repositories that the Celery project\r\nmaintains or other repositories that are dependencies of Celery.\r\n\r\nIf you don't know how to mention issues, please refer to Github's documentation\r\non the subject: https://help.github.com/en/articles/autolinked-references-and-urls#issues-and-pull-requests\r\n-->\r\n\r\n#### Related Issues\r\n\r\nhttps://github.com/celery/celery/issues/8456\r\n\r\n#### Possible Duplicates\r\n\r\n- None\r\n\r\n## Environment & Settings\r\n<!-- Include the contents of celery --version below -->\r\n**Celery version**: 5.3.6 (emerald-rush)\r\n<!-- Include the output of celery -A proj report below -->\r\n<details>\r\n<summary><b><code>celery report</code> Output:</b></summary>\r\n<p>\r\n\r\n```\r\nsoftware -> celery:5.3.6 (emerald-rush) kombu:5.3.4 py:3.8.10\r\n            billiard:4.2.0 redis:5.0.1\r\nplatform -> system:Darwin arch:64bit\r\n            kernel version:23.1.0 imp:CPython\r\nloader   -> celery.loaders.app.AppLoader\r\nsettings -> transport:redis results:redis://0.0.0.0:6479/\r\n\r\nbroker_url: 'redis://0.0.0.0:6479//'\r\nresult_backend: 'redis://0.0.0.0:6479/'\r\ndeprecated_settings: None\r\ntask_allow_error_cb_on_chord_header: True\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n# Steps to Reproduce\r\n\r\n## Required Dependencies\r\n<!-- Please fill the required dependencies to reproduce this issue -->\r\n- **Minimal Python Version**: N/A or Unknown\r\n- **Minimal Celery Version**: 5.3.1\r\n- **Minimal Kombu Version**: N/A or Unknown\r\n- **Minimal Broker Version**: N/A or Unknown\r\n- **Minimal Result Backend Version**: N/A or Unknown\r\n- **Minimal OS and/or Kernel Version**: N/A or Unknown\r\n- **Minimal Broker Client Version**: N/A or Unknown\r\n- **Minimal Result Backend Client Version**: N/A or Unknown\r\n\r\n### Python Packages\r\n<!-- Please fill the contents of pip freeze below -->\r\n<details>\r\n<summary><b><code>pip freeze</code> Output:</b></summary>\r\n<p>\r\n\r\n```\r\naiohttp==3.8.5\r\naiosignal==1.3.1\r\namqp==5.2.0\r\nasgiref==3.6.0\r\nastroid==2.15.2\r\nasync-timeout==4.0.3\r\nattrs==22.2.0\r\nautopep8==1.5.5\r\nbackports.zoneinfo==0.2.1\r\nbandit==1.7.5\r\nbilliard==4.2.0\r\nblack==23.7.0\r\nboto3-stubs==1.19.12.post1\r\nbotocore-stubs==1.29.107\r\ncelery==5.3.6\r\ncelery-stubs==0.1.3\r\ncertifi==2022.12.7\r\ncfgv==3.3.1\r\ncharset-normalizer==3.1.0\r\nclick==8.1.7\r\nclick-didyoumean==0.3.0\r\nclick-plugins==1.1.1\r\nclick-repl==0.3.0\r\ncoreapi==2.3.3\r\ncoreschema==0.0.4\r\ndata-science-types==0.2.23\r\ndill==0.3.6\r\ndistlib==0.3.6\r\nDjango==4.2\r\ndjango-filter-stubs==0.1.3\r\ndjango-stubs==1.15.0\r\ndjango-stubs-ext==0.8.0\r\ndjangorestframework==3.14.0\r\ndjangorestframework-stubs==1.9.1\r\ndrf-yasg==1.20.3\r\nfactory-boy==3.2.1\r\nFaker==18.3.4\r\nfilelock==3.10.7\r\nflake8==3.8.4\r\nfrozenlist==1.4.0\r\nfuzzywuzzy-stubs==0.0.1\r\ngitdb==4.0.10\r\nGitPython==3.1.31\r\ngraphene-stubs==0.15\r\nidentify==2.5.22\r\nidna==3.4\r\ninflection==0.5.1\r\nisort==5.12.0\r\nitypes==1.2.0\r\njedi==0.17.2\r\nJinja2==3.1.2\r\nkombu==5.3.4\r\nlazy-object-proxy==1.9.0\r\nmarkdown-it-py==2.2.0\r\nMarkupSafe==2.1.2\r\nmccabe==0.6.1\r\nmdurl==0.1.2\r\nmultidict==6.0.4\r\nmypy==1.1.1\r\nmypy-extensions==1.0.0\r\nnodeenv==1.7.0\r\npackaging==23.0\r\nparso==0.7.1\r\npathspec==0.11.1\r\npbr==5.11.1\r\npip-licenses==3.5.5\r\nplatformdirs==3.2.0\r\npluggy==1.0.0\r\npre-commit==2.7.1\r\nprompt-toolkit==3.0.41\r\nPTable==0.9.2\r\npycodestyle==2.6.0\r\npydocstyle==6.3.0\r\npyflakes==2.2.0\r\nPygments==2.14.0\r\npylint==2.17.2\r\npython-dateutil==2.8.2\r\npython-jsonrpc-server==0.4.0\r\npython-language-server==0.36.2\r\npytoolconfig==1.2.5\r\npytz==2023.3\r\nPyYAML==6.0\r\nratelimit-stubs==2.2.1\r\nredis==5.0.1\r\nregex==2019.11.1\r\nrequests==2.28.2\r\nrich==13.3.3\r\nrope==1.7.0\r\nruamel.yaml==0.17.21\r\nruamel.yaml.clib==0.2.7\r\nsix==1.16.0\r\nsmmap==5.0.0\r\nsnowballstemmer==2.2.0\r\nsqlparse==0.4.3\r\nstevedore==5.0.0\r\ntoml==0.10.2\r\ntomli==2.0.1\r\ntomlkit==0.11.7\r\ntypes-awscrt==0.16.13.post1\r\ntypes-beautifulsoup4==4.10.20\r\ntypes-docutils==0.19.1.7\r\ntypes-pytz==2023.3.0.0\r\ntypes-PyYAML==5.4.12\r\ntypes-requests==2.25.12\r\ntypes-setuptools==67.3.0.2\r\ntypes-six==0.1.9\r\ntyping_extensions==4.5.0\r\ntzdata==2023.3\r\nujson==5.7.0\r\nuritemplate==4.1.1\r\nurllib3==1.26.15\r\nvine==5.1.0\r\nvirtualenv==20.21.0\r\nwcwidth==0.2.12\r\nwrapt==1.15.0\r\nyapf==0.32.0\r\nyarl==1.8.2\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n### Other Dependencies\r\n<!--\r\nPlease provide system dependencies, configuration files\r\nand other dependency information if applicable\r\n-->\r\n<details>\r\n<p>\r\nN/A\r\n</p>\r\n</details>\r\n\r\n## Minimally Reproducible Test Case\r\n<!--\r\nPlease provide a reproducible test case.\r\nRefer to the Reporting Bugs section in our contribution guide.\r\n\r\nWe prefer submitting test cases in the form of a PR to our integration test suite.\r\nIf you can provide one, please mention the PR number below.\r\nIf not, please attach the most minimal code example required to reproduce the issue below.\r\nIf the test case is too large, please include a link to a gist or a repository below.\r\n-->\r\n\r\n<details>\r\n<p>\r\n\r\n```python\r\nfrom celery import Celery, chain, chord, signature, group\r\n\r\napp = Celery(\r\n    \"celery_bug\", backend=\"redis://0.0.0.0:6479/\", broker=\"redis://0.0.0.0:6479/\"\r\n)\r\n\r\napp.conf.task_allow_error_cb_on_chord_header = True\r\n\r\n\r\n@app.task(bind=True)\r\ndef orig_task(self, arg):\r\n    chord_headers = group([chord_header.s(arg=f\"arg{i}\") for i in range(5)])\r\n    replacement_chord = chord(chord_headers, chord_body.s())\r\n    return self.replace(replacement_chord)\r\n\r\n\r\n@app.task\r\ndef chord_header(arg):\r\n    return f\"header: {arg}\"\r\n\r\n\r\n@app.task\r\ndef chord_body(arg):\r\n    return f\"body: {arg}]\"\r\n\r\n\r\n@app.task\r\ndef handle_error(*args, **kwargs):\r\n    print(f\"handle error called with args {args} kwargs {kwargs}\")\r\n\r\n\r\ndef main():\r\n    print(f\"hello world\")\r\n    res = orig_task.apply_async(args=[\"spam\"], link_error=handle_error.s())\r\n    print(f\"RESULT: {res.get()}\")\r\n\r\n\r\nif __name__ == \"__main__\":\r\n    main()\r\n\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n# Expected Behavior\r\n<!-- Describe in detail what you expect to happen -->\r\nI would expect the `orig_task` to be replaced with `replacement_chord` and give expected output.\r\n\r\nThis is the expected output that I do see if `task_allow_error_cb_on_chord_header` is `False`, or if the `orig_task` is called without the `link_error=` callback:  \r\n\r\n```\r\n$ poetry run python celery_bug.py \r\nhello world\r\nRESULT: body: ['header: arg0', 'header: arg1', 'header: arg2', 'header: arg3', 'header: arg4']]\r\n```\r\n# Actual Behavior\r\n<!--\r\nDescribe in detail what actually happened.\r\nPlease include a backtrace and surround it with triple backticks (```).\r\nIn addition, include the Celery daemon logs, the broker logs,\r\nthe result backend logs and system logs below if they will help us debug\r\nthe issue.\r\n-->\r\nInstead, I get this `AttributeError`:\r\n```\r\n$ poetry run python celery_bug.py \r\nhello world\r\nTraceback (most recent call last):\r\n  File \"celery_bug.py\", line 39, in <module>\r\n    main()\r\n  File \"celery_bug.py\", line 35, in main\r\n    print(f\"RESULT: {res.get()}\")\r\n  File \"/Users/robertgalloway/Library/Caches/pypoetry/virtualenvs/rpg-play-aJQQ1jqR-py3.8/lib/python3.8/site-packages/celery/result.py\", line 251, in get\r\n    return self.backend.wait_for_pending(\r\n  File \"/Users/robertgalloway/Library/Caches/pypoetry/virtualenvs/rpg-play-aJQQ1jqR-py3.8/lib/python3.8/site-packages/celery/backends/asynchronous.py\", line 223, in wait_for_pending\r\n    return result.maybe_throw(callback=callback, propagate=propagate)\r\n  File \"/Users/robertgalloway/Library/Caches/pypoetry/virtualenvs/rpg-play-aJQQ1jqR-py3.8/lib/python3.8/site-packages/celery/result.py\", line 365, in maybe_throw\r\n    self.throw(value, self._to_remote_traceback(tb))\r\n  File \"/Users/robertgalloway/Library/Caches/pypoetry/virtualenvs/rpg-play-aJQQ1jqR-py3.8/lib/python3.8/site-packages/celery/result.py\", line 358, in throw\r\n    self.on_ready.throw(*args, **kwargs)\r\n  File \"/Users/robertgalloway/Library/Caches/pypoetry/virtualenvs/rpg-play-aJQQ1jqR-py3.8/lib/python3.8/site-packages/vine/promises.py\", line 235, in throw\r\n    reraise(type(exc), exc, tb)\r\n  File \"/Users/robertgalloway/Library/Caches/pypoetry/virtualenvs/rpg-play-aJQQ1jqR-py3.8/lib/python3.8/site-packages/vine/utils.py\", line 27, in reraise\r\n    raise value\r\nAttributeError: 'dict' object has no attribute 'clone'\r\n```\r\n\r\nI suspect the error is related to this code in the `_chord.link_error()` method:\r\n```python\r\n        if self.app.conf.task_allow_error_cb_on_chord_header:\r\n            for task in maybe_list(self.tasks) or []:\r\n                task.link_error(errback.clone(immutable=True))\r\n```\r\n\n",
        "hints_text": "previous related fix  https://github.com/celery/celery/pull/8463 ",
        "created_at": "2023-12-07T12:10:06Z",
        "version": "5.3",
        "PASS_TO_PASS": [],
        "FAIL_TO_PASS": [
            "t/unit/tasks/test_canvas.py"
        ]
    },
    {
        "repo": "celery/celery",
        "pull_number": 8489,
        "instance_id": "celery__celery-8489",
        "issue_numbers": [
            "6608"
        ],
        "base_commit": "b6a5bdb8b698dbe2a0848e34f76133f2950c5a82",
        "patch": "diff --git a/celery/bin/control.py b/celery/bin/control.py\nindex f7bba96ddf0..38a917ea0f2 100644\n--- a/celery/bin/control.py\n+++ b/celery/bin/control.py\n@@ -1,5 +1,6 @@\n \"\"\"The ``celery control``, ``. inspect`` and ``. status`` programs.\"\"\"\n from functools import partial\n+from typing import Literal\n \n import click\n from kombu.utils.json import dumps\n@@ -39,18 +40,69 @@ def _consume_arguments(meta, method, args):\n         args[:] = args[i:]\n \n \n-def _compile_arguments(action, args):\n-    meta = Panel.meta[action]\n+def _compile_arguments(command, args):\n+    meta = Panel.meta[command]\n     arguments = {}\n     if meta.args:\n         arguments.update({\n-            k: v for k, v in _consume_arguments(meta, action, args)\n+            k: v for k, v in _consume_arguments(meta, command, args)\n         })\n     if meta.variadic:\n         arguments.update({meta.variadic: args})\n     return arguments\n \n \n+_RemoteControlType = Literal['inspect', 'control']\n+\n+\n+def _verify_command_name(type_: _RemoteControlType, command: str) -> None:\n+    choices = _get_commands_of_type(type_)\n+\n+    if command not in choices:\n+        command_listing = \", \".join(choices)\n+        raise click.UsageError(\n+            message=f'Command {command} not recognized. Available {type_} commands: {command_listing}',\n+        )\n+\n+\n+def _list_option(type_: _RemoteControlType):\n+    def callback(ctx: click.Context, param, value) -> None:\n+        if not value:\n+            return\n+        choices = _get_commands_of_type(type_)\n+\n+        formatter = click.HelpFormatter()\n+\n+        with formatter.section(f'{type_.capitalize()} Commands'):\n+            command_list = []\n+            for command_name, info in choices.items():\n+                if info.signature:\n+                    command_preview = f'{command_name} {info.signature}'\n+                else:\n+                    command_preview = command_name\n+                command_list.append((command_preview, info.help))\n+            formatter.write_dl(command_list)\n+        ctx.obj.echo(formatter.getvalue(), nl=False)\n+        ctx.exit()\n+\n+    return click.option(\n+        '--list',\n+        is_flag=True,\n+        help=f'List available {type_} commands and exit.',\n+        expose_value=False,\n+        is_eager=True,\n+        callback=callback,\n+    )\n+\n+\n+def _get_commands_of_type(type_: _RemoteControlType) -> dict:\n+    command_name_info_pairs = [\n+        (name, info) for name, info in Panel.meta.items()\n+        if info.type == type_ and info.visible\n+    ]\n+    return dict(sorted(command_name_info_pairs))\n+\n+\n @click.command(cls=CeleryCommand)\n @click.option('-t',\n               '--timeout',\n@@ -96,10 +148,8 @@ def status(ctx, timeout, destination, json, **kwargs):\n \n @click.command(cls=CeleryCommand,\n                context_settings={'allow_extra_args': True})\n-@click.argument(\"action\", type=click.Choice([\n-    name for name, info in Panel.meta.items()\n-    if info.type == 'inspect' and info.visible\n-]))\n+@click.argument('command')\n+@_list_option('inspect')\n @click.option('-t',\n               '--timeout',\n               cls=CeleryOption,\n@@ -121,19 +171,19 @@ def status(ctx, timeout, destination, json, **kwargs):\n               help='Use json as output format.')\n @click.pass_context\n @handle_preload_options\n-def inspect(ctx, action, timeout, destination, json, **kwargs):\n-    \"\"\"Inspect the worker at runtime.\n+def inspect(ctx, command, timeout, destination, json, **kwargs):\n+    \"\"\"Inspect the workers by sending them the COMMAND inspect command.\n \n     Availability: RabbitMQ (AMQP) and Redis transports.\n     \"\"\"\n+    _verify_command_name('inspect', command)\n     callback = None if json else partial(_say_remote_command_reply, ctx,\n                                          show_reply=True)\n-    arguments = _compile_arguments(action, ctx.args)\n+    arguments = _compile_arguments(command, ctx.args)\n     inspect = ctx.obj.app.control.inspect(timeout=timeout,\n                                           destination=destination,\n                                           callback=callback)\n-    replies = inspect._request(action,\n-                               **arguments)\n+    replies = inspect._request(command, **arguments)\n \n     if not replies:\n         raise CeleryCommandException(\n@@ -153,10 +203,8 @@ def inspect(ctx, action, timeout, destination, json, **kwargs):\n \n @click.command(cls=CeleryCommand,\n                context_settings={'allow_extra_args': True})\n-@click.argument(\"action\", type=click.Choice([\n-    name for name, info in Panel.meta.items()\n-    if info.type == 'control' and info.visible\n-]))\n+@click.argument('command')\n+@_list_option('control')\n @click.option('-t',\n               '--timeout',\n               cls=CeleryOption,\n@@ -178,16 +226,17 @@ def inspect(ctx, action, timeout, destination, json, **kwargs):\n               help='Use json as output format.')\n @click.pass_context\n @handle_preload_options\n-def control(ctx, action, timeout, destination, json):\n-    \"\"\"Workers remote control.\n+def control(ctx, command, timeout, destination, json):\n+    \"\"\"Send the COMMAND control command to the workers.\n \n     Availability: RabbitMQ (AMQP), Redis, and MongoDB transports.\n     \"\"\"\n+    _verify_command_name('control', command)\n     callback = None if json else partial(_say_remote_command_reply, ctx,\n                                          show_reply=True)\n     args = ctx.args\n-    arguments = _compile_arguments(action, args)\n-    replies = ctx.obj.app.control.broadcast(action, timeout=timeout,\n+    arguments = _compile_arguments(command, args)\n+    replies = ctx.obj.app.control.broadcast(command, timeout=timeout,\n                                             destination=destination,\n                                             callback=callback,\n                                             reply=True,\ndiff --git a/t/unit/bin/proj/app_with_custom_cmds.py b/t/unit/bin/proj/app_with_custom_cmds.py\nnew file mode 100644\nindex 00000000000..db96b99e700\n--- /dev/null\n+++ b/t/unit/bin/proj/app_with_custom_cmds.py\n@@ -0,0 +1,24 @@\n+from celery import Celery\n+from celery.worker.control import control_command, inspect_command\n+\n+\n+@control_command(\n+    args=[('a', int), ('b', int)],\n+    signature='a b',\n+)\n+def custom_control_cmd(state, a, b):\n+    \"\"\"Ask the workers to reply with a and b.\"\"\"\n+    return {'ok': f'Received {a} and {b}'}\n+\n+\n+@inspect_command(\n+    args=[('x', int)],\n+    signature='x',\n+)\n+def custom_inspect_cmd(state, x):\n+    \"\"\"Ask the workers to reply with x.\"\"\"\n+    return {'ok': f'Received {x}'}\n+\n+\n+app = Celery(set_as_current=False)\n+app.config_from_object('t.integration.test_worker_config')\n",
        "test_patch": "diff --git a/t/unit/app/test_preload_cli.py b/t/unit/app/test_preload_cli.py\nindex a2241a1400d..9932f5b88d4 100644\n--- a/t/unit/app/test_preload_cli.py\n+++ b/t/unit/app/test_preload_cli.py\n@@ -1,34 +1,41 @@\n+import contextlib\n+from typing import Tuple\n+from unittest.mock import patch\n+\n+import pytest\n from click.testing import CliRunner\n \n from celery.bin.celery import celery\n \n \n-def test_preload_options(isolated_cli_runner: CliRunner):\n-    # Verify commands like shell and purge can accept preload options.\n-    # Projects like Pyramid-Celery's ini option should be valid preload\n-    # options.\n-\n-    # TODO: Find a way to run these separate invoke and assertions\n-    # such that order does not matter. Currently, running\n-    # the \"t.unit.bin.proj.pyramid_celery_app\" first seems\n-    # to result in cache or memoization of the option.\n-    # As a result, the expected exception is not raised when\n-    # the invoke on \"t.unit.bin.proj.app\" is run as a second\n-    # call.\n+@pytest.fixture(autouse=True)\n+def reset_command_params_between_each_test():\n+    with contextlib.ExitStack() as stack:\n+        for command in celery.commands.values():\n+            # We only need shallow copy -- preload options are appended to the list,\n+            # existing options are kept as-is\n+            params_copy = command.params[:]\n+            patch_instance = patch.object(command, \"params\", params_copy)\n+            stack.enter_context(patch_instance)\n \n-    res_without_preload = isolated_cli_runner.invoke(\n-        celery,\n-        [\"-A\", \"t.unit.bin.proj.app\", \"purge\", \"-f\", \"--ini\", \"some_ini.ini\"],\n-        catch_exceptions=True,\n-    )\n+        yield\n \n-    assert \"No such option: --ini\" in res_without_preload.stdout\n-    assert res_without_preload.exit_code == 2\n \n+@pytest.mark.parametrize(\n+    \"subcommand_with_params\",\n+    [\n+        (\"purge\", \"-f\"),\n+        (\"shell\",),\n+    ]\n+)\n+def test_preload_options(subcommand_with_params: Tuple[str, ...], isolated_cli_runner: CliRunner):\n+    # Verify commands like shell and purge can accept preload options.\n+    # Projects like Pyramid-Celery's ini option should be valid preload\n+    # options.\n     res_without_preload = isolated_cli_runner.invoke(\n         celery,\n-        [\"-A\", \"t.unit.bin.proj.app\", \"shell\", \"--ini\", \"some_ini.ini\"],\n-        catch_exceptions=True,\n+        [\"-A\", \"t.unit.bin.proj.app\", *subcommand_with_params, \"--ini\", \"some_ini.ini\"],\n+        catch_exceptions=False,\n     )\n \n     assert \"No such option: --ini\" in res_without_preload.stdout\n@@ -39,25 +46,11 @@ def test_preload_options(isolated_cli_runner: CliRunner):\n         [\n             \"-A\",\n             \"t.unit.bin.proj.pyramid_celery_app\",\n-            \"purge\",\n-            \"-f\",\n+            *subcommand_with_params,\n             \"--ini\",\n             \"some_ini.ini\",\n         ],\n-        catch_exceptions=True,\n+        catch_exceptions=False,\n     )\n \n-    assert res_with_preload.exit_code == 0\n-\n-    res_with_preload = isolated_cli_runner.invoke(\n-        celery,\n-        [\n-            \"-A\",\n-            \"t.unit.bin.proj.pyramid_celery_app\",\n-            \"shell\",\n-            \"--ini\",\n-            \"some_ini.ini\",\n-        ],\n-        catch_exceptions=True,\n-    )\n-    assert res_with_preload.exit_code == 0\n+    assert res_with_preload.exit_code == 0, res_with_preload.stdout\ndiff --git a/t/unit/bin/test_control.py b/t/unit/bin/test_control.py\nnew file mode 100644\nindex 00000000000..6d3704e9dc2\n--- /dev/null\n+++ b/t/unit/bin/test_control.py\n@@ -0,0 +1,82 @@\n+import os\n+import re\n+from unittest.mock import patch\n+\n+import pytest\n+from click.testing import CliRunner\n+\n+from celery.bin.celery import celery\n+from celery.platforms import EX_UNAVAILABLE\n+\n+_GLOBAL_OPTIONS = ['-A', 't.unit.bin.proj.app_with_custom_cmds', '--broker', 'memory://']\n+_INSPECT_OPTIONS = ['--timeout', '0']  # Avoid waiting for the zero workers to reply\n+\n+\n+@pytest.fixture(autouse=True)\n+def clean_os_environ():\n+    # Celery modifies os.environ when given the CLI option --broker memory://\n+    # This interferes with other tests, so we need to reset os.environ\n+    with patch.dict(os.environ, clear=True):\n+        yield\n+\n+\n+@pytest.mark.parametrize(\n+    ('celery_cmd', 'custom_cmd'),\n+    [\n+        ('inspect', ('custom_inspect_cmd', '123')),\n+        ('control', ('custom_control_cmd', '123', '456')),\n+    ],\n+)\n+def test_custom_remote_command(celery_cmd, custom_cmd, isolated_cli_runner: CliRunner):\n+    res = isolated_cli_runner.invoke(\n+        celery,\n+        [*_GLOBAL_OPTIONS, celery_cmd, *_INSPECT_OPTIONS, *custom_cmd],\n+        catch_exceptions=False,\n+    )\n+    assert res.exit_code == EX_UNAVAILABLE, (res, res.stdout)\n+    assert res.stdout.strip() == 'Error: No nodes replied within time constraint'\n+\n+\n+@pytest.mark.parametrize(\n+    ('celery_cmd', 'remote_cmd'),\n+    [\n+        # Test nonexistent commands\n+        ('inspect', 'this_command_does_not_exist'),\n+        ('control', 'this_command_does_not_exist'),\n+        # Test commands that exist, but are of the wrong type\n+        ('inspect', 'custom_control_cmd'),\n+        ('control', 'custom_inspect_cmd'),\n+    ],\n+)\n+def test_unrecognized_remote_command(celery_cmd, remote_cmd, isolated_cli_runner: CliRunner):\n+    res = isolated_cli_runner.invoke(\n+        celery,\n+        [*_GLOBAL_OPTIONS, celery_cmd, *_INSPECT_OPTIONS, remote_cmd],\n+        catch_exceptions=False,\n+    )\n+    assert res.exit_code == 2, (res, res.stdout)\n+    assert f'Error: Command {remote_cmd} not recognized. Available {celery_cmd} commands: ' in res.stdout\n+\n+\n+_expected_inspect_regex = (\n+    '\\n  custom_inspect_cmd x\\\\s+Ask the workers to reply with x\\\\.\\n'\n+)\n+_expected_control_regex = (\n+    '\\n  custom_control_cmd a b\\\\s+Ask the workers to reply with a and b\\\\.\\n'\n+)\n+\n+\n+@pytest.mark.parametrize(\n+    ('celery_cmd', 'expected_regex'),\n+    [\n+        ('inspect', re.compile(_expected_inspect_regex, re.MULTILINE)),\n+        ('control', re.compile(_expected_control_regex, re.MULTILINE)),\n+    ],\n+)\n+def test_listing_remote_commands(celery_cmd, expected_regex, isolated_cli_runner: CliRunner):\n+    res = isolated_cli_runner.invoke(\n+        celery,\n+        [*_GLOBAL_OPTIONS, celery_cmd, '--list'],\n+    )\n+    assert res.exit_code == 0, (res, res.stdout)\n+    assert expected_regex.search(res.stdout)\n",
        "problem_statement": "Celery 5 custom inspect commands doesn't work in the CLI\n<!--\nPlease fill this template entirely and do not erase parts of it.\nWe reserve the right to close without a response\nbug reports which are incomplete.\n-->\n\n\n# Checklist\n<!--\nTo check an item on the list replace [ ] with [x].\n-->\n\n\n* [x] I have verified that the issue exists against the `master` branch of Celery.\n* [x] This has already been asked to the [discussion group](https://groups.google.com/forum/#!forum/celery-users) first.\n* [x] I have read the relevant section in the\n  [contribution guide](http://docs.celeryproject.org/en/latest/contributing.html#other-bugs)\n  on reporting bugs.\n* [x] I have checked the [issues list](https://github.com/celery/celery/issues?q=is%3Aissue+label%3A%22Issue+Type%3A+Bug+Report%22+-label%3A%22Category%3A+Documentation%22)\n  for similar or identical bug reports.\n* [x] I have checked the [pull requests list](https://github.com/celery/celery/pulls?q=is%3Apr+label%3A%22PR+Type%3A+Bugfix%22+-label%3A%22Category%3A+Documentation%22)\n  for existing proposed fixes.\n* [x] I have checked the [commit log](https://github.com/celery/celery/commits/master)\n  to find out if the bug was already fixed in the master branch.\n* [x] I have included all related issues and possible duplicate issues\n  in this issue (If there are none, check this box anyway).\n\n## Mandatory Debugging Information\n* [ ] I have included the output of ``celery -A proj report`` in the issue.\n    (if you are not able to do this, then at least specify the Celery\n     version affected).\n* [ ] I have verified that the issue exists against the `master` branch of Celery.\n* [ ] I have included the contents of ``pip freeze`` in the issue.\n* [ ] I have included all the versions of all the external dependencies required\n  to reproduce this bug.\n\n## Optional Debugging Information\n<!--\nTry some of the below if you think they are relevant.\nIt will help us figure out the scope of the bug and how many users it affects.\n-->\n\n\n* [ ] I have tried reproducing the issue on more than one Python version\n  and/or implementation.\n* [ ] I have tried reproducing the issue on more than one message broker and/or\n  result backend.\n* [ ] I have tried reproducing the issue on more than one version of the message\n  broker and/or result backend.\n* [ ] I have tried reproducing the issue on more than one operating system.\n* [ ] I have tried reproducing the issue on more than one workers pool.\n* [ ] I have tried reproducing the issue with autoscaling, retries,\n  ETA/Countdown & rate limits disabled.\n* [ ] I have tried reproducing the issue after downgrading\n  and/or upgrading Celery and its dependencies.\n\n## Related Issues and Possible Duplicates\n<!--\nPlease make sure to search and mention any related issues\nor possible duplicates to this issue as requested by the checklist above.\n\nThis may or may not include issues in other repositories that the Celery project\nmaintains or other repositories that are dependencies of Celery.\n\nIf you don't know how to mention issues, please refer to Github's documentation\non the subject: https://help.github.com/en/articles/autolinked-references-and-urls#issues-and-pull-requests\n-->\n\n#### Related Issues\n* None\n\n#### Possible Duplicates\n* None\n\n## Environment & Settings\n<!-- Include the contents of celery --version below -->\n**Celery version**:\n<!-- Include the output of celery -A proj report below -->\n<details>\n<summary><b><code>celery report</code> Output:</b></summary>\n<p>\nsoftware -> celery:5.0.5 (singularity) kombu:5.0.2 py:3.7.5\n            billiard:3.6.3.0 py-amqp:5.0.3\nplatform -> system:Linux arch:64bit, ELF\n            kernel version:4.4.0-19041-Microsoft imp:CPython\nloader   -> celery.loaders.default.Loader\nsettings -> transport:amqp results:disabled\n\ndeprecated_settings: None\n\n\n```\n\n```\n\n</p>\n</details>\n\n# Steps to Reproduce\n## Required Dependencies\n<!-- Please fill the required dependencies to reproduce this issue -->\n\n\n* **Minimal Python Version**: N/A or Unknown\n* **Minimal Celery Version**: 5\n* **Minimal Kombu Version**: N/A or Unknown\n* **Minimal Broker Version**: N/A or Unknown\n* **Minimal Result Backend Version**: N/A or Unknown\n* **Minimal OS and/or Kernel Version**: N/A or Unknown\n* **Minimal Broker Client Version**: N/A or Unknown\n* **Minimal Result Backend Client Version**: N/A or Unknown\n\n### Python Packages\n<!-- Please fill the contents of pip freeze below -->\n<details>\n<summary><b><code>pip freeze</code> Output:</b></summary>\n\nabsl-py==0.9.0\naiohttp==3.6.2\naiomisc==11.0.0\namqp==5.0.3\nappdirs==1.4.4\nasgiref==3.2.10\nasn1crypto==0.24.0\nastor==0.8.1\nasync-timeout==3.0.1\natomicwrites==1.3.0\nattrs==19.3.0\nauth0-python==3.9.1\naws2-wrap==1.1.4\nawscli==1.14.44\nBabel==2.8.0\nbackcall==0.1.0\nbilliard==3.6.3.0\nboto3==1.14.19\nboto3-stubs==1.14.19.0\nbotocore==1.17.63\nBrotli==1.0.9\ncachetools==4.0.0\ncelery==5.0.5\ncertifi==2019.11.28\ncffi==1.14.0\nchardet==3.0.4\nclick==7.1.2\nclick-didyoumean==0.0.3\nclick-plugins==1.1.1\nclick-repl==0.1.6\ncolorama==0.3.7\ncolorlog==4.4.0\nconvertdate==2.2.2\ncryptography==2.7\nddtrace==0.44.0\ndecorator==4.4.2\ndefusedxml==0.6.0\nDjango==3.1.2\ndjango-celery-results==1.0.4\ndjango-cors-headers==3.1.0\ndjango-debug-toolbar==3.1.1\ndjango-filter==2.1.0\ndjango-prometheus==1.0.15\ndjango-rest-auth==0.9.5\ndjango-rest-framework-condition==0.1.1\ndjangorestframework==3.12.1\ndjangorestframework-jwt==1.11.0\ndocutils==0.15.2\necdsa==0.15\nffmpeg-python==0.2.0\nfitparse==1.1.0\nflower==0.9.3\nfusepy==3.0.1\nfuture==0.18.2\ngast==0.2.2\ngitdb==4.0.2\ngitdb2==3.0.0\nGitPython==3.1.0\nglfw==1.8.2\ngoogle-auth==1.11.3\ngoogle-auth-oauthlib==0.4.1\ngoogle-pasta==0.2.0\ngprof2dot==2019.11.30\ngraphqlclient==0.2.4\ngrpcio==1.27.2\nh5py==2.10.0\nholidays==0.10.1\nidna==2.6\nimageio-ffmpeg==0.3.0\nimportlib-metadata==1.5.0\nimutils==0.5.2\nintervaltree==3.1.0\nipython==7.6.1\nipython-genutils==0.2.0\njedi==0.16.0\njmespath==0.9.5\njoblib==0.14.1\nKeras-Applications==1.0.8\nKeras-Preprocessing==1.1.0\nkeyring==10.6.0\nkeyrings.alt==3.0\nkombu==5.0.2\nkubernetes==12.0.0\nlogzio-python-handler==2.0.13\nlxml==4.4.2\nMarkdown==3.2.1\nmemory-profiler==0.57.0\nmore-itertools==8.2.0\nmultidict==4.7.5\nmunkres==1.1.2\nmypy-boto3==1.14.19.0\nmypy-boto3-cloudformation==1.14.19.0\nmypy-boto3-dynamodb==1.14.19.0\nmypy-boto3-ec2==1.14.19.0\nmypy-boto3-lambda==1.14.19.0\nmypy-boto3-rds==1.14.19.0\nmypy-boto3-s3==1.14.19.0\nmypy-boto3-sqs==1.14.19.0\nnumpy==1.17.0\noauthlib==3.1.0\nolefile==0.45.1\nopencv-python==3.4.5.20\nopt-einsum==3.2.0\npackaging==20.3\npandas==1.1.4\nparso==0.6.2\npdfkit==0.6.1\npexpect==4.8.0\npickleshare==0.7.5\nPillow==7.1.2\npipdeptree==1.0.0\npluggy==0.13.1\npprofile==2.0.2\nprometheus-client==0.7.1\nprompt-toolkit==2.0.10\nprotobuf==3.11.3\npsutil==5.7.0\npsycopg2-binary==2.8.3\nptyprocess==0.6.0\npy==1.8.1\npyasn1==0.4.8\npyasn1-modules==0.2.8\npycparser==2.20\npycrypto==2.6.1\npyee==7.0.4\nPygments==2.6.1\npygobject==3.26.1\nPyJWT==1.7.1\nPyMeeus==0.3.7\nPyOpenGL==3.1.0\npyparsing==2.4.6\npyperclip==1.7.0\npyppeteer==0.2.2\npyquaternion==0.9.5\nPySocks==1.7.1\npytest==4.6.5\npytest-django==3.10.0\npytest-django-ordering==1.2.0\npytest-profiling==1.7.0\npython-apt==1.6.5+ubuntu0.2\npython-dateutil==2.8.0\npython-dotenv==0.10.3\npython-http-client==3.2.6\npython-jose==3.0.1\npython-json-logger==0.1.11\npython-memcached==1.59\npython3-openid==3.1.0\npytz==2019.3\npyxdg==0.25\nPyYAML==5.3.1\nredis==3.3.11\nrequests==2.22.0\nrequests-oauthlib==1.3.0\nretry==0.9.2\nroman==2.0.0\nrsa==4.0\ns3transfer==0.3.3\nscikit-fmm==2019.1.30\nscikit-learn==0.23.1\nscipy==1.3.1\nSecretStorage==2.3.1\nsendgrid==6.4.1\nShapely==1.6.4.post2\nsix==1.12.0\nsmmap==3.0.1\nsmmap2==3.0.1\nsocial-auth-app-django==3.1.0\nsocial-auth-core==3.2.0\nsortedcontainers==2.3.0\nsqlparse==0.3.1\nstarkbank-ecdsa==1.1.0\ntenacity==6.3.1\ntensorboard==2.0.2\ntensorflow==2.0.0\ntensorflow-estimator==2.0.1\ntermcolor==1.1.0\nthreadpoolctl==2.1.0\ntornado==5.1.1\ntqdm==4.56.0\ntraitlets==4.3.3\ntripy==1.0.0\ntwilio==6.29.3\ntyping-extensions==3.7.4.3\nunattended-upgrades==0.1\nurllib3==1.25.8\nuWSGI==2.0.18\nvine==5.0.0\nwcwidth==0.1.8\nwebsocket-client==0.57.0\nwebsockets==8.1\nWerkzeug==1.0.0\nwrapt==1.12.1\nxgboost==0.90\nxlrd==1.2.0\nXlsxWriter==1.2.8\nxxhash==1.3.0\nyappi==1.0\nyarl==1.4.2\nzipp==3.1.0\n<p>\n\n```\n\n```\n\n</p>\n</details>\n\n### Other Dependencies\n<!--\nPlease provide system dependencies, configuration files\nand other dependency information if applicable\n-->\n<details>\n<p>\nN/A\n</p>\n</details>\n\n## Minimally Reproducible Test Case\n<!--\nPlease provide a reproducible test case.\nRefer to the Reporting Bugs section in our contribution guide.\n\nWe prefer submitting test cases in the form of a PR to our integration test suite.\nIf you can provide one, please mention the PR number below.\nIf not, please attach the most minimal code example required to reproduce the issue below.\nIf the test case is too large, please include a link to a gist or a repository below.\n-->\n\n<details>\n<p>\n\n```python\n\n```\n\n</p>\n</details>\n\n# Expected Behavior\n<!-- Describe in detail what you expect to happen -->\n\n# Actual Behavior\n<!--\nDescribe in detail what actually happened.\nPlease include a backtrace and surround it with triple backticks (```).\nIn addition, include the Celery daemon logs, the broker logs,\nthe result backend logs and system logs below if they will help us debug\nthe issue.\n-->\n\nHi, I think there is a bug with version 5+.\nWhen using the guide in the docs for writing custom control commands and trying to run it from the CLI, it fails. When running this command from a python script, it is working (with broadcast). When using celery 4.4.3 on the same code, it also works.\nThe guide: https://docs.celeryproject.org/en/stable/userguide/workers.html#writing-your-own-remote-control-commands\nthe error:\n$ celery -A route inspect current_prefetch_count\nUsage: celery inspect [OPTIONS] [report|conf|query_task|clock|ping|stats|sched\nuled|reserved|active|revoked|registered|objgraph|memsamp\nle|memdump|active_queues]\nTry 'celery inspect --help' for help.\n\nError: Invalid value for '[report|conf|query_task|clock|ping|stats|scheduled|reserved|active|revoked|registered|objgraph|memsample|memdump|active_queues]': invalid choice: current_prefetch_count. (choose from report, conf, query_task, clock, ping, stats, scheduled, rese\nrved, active, revoked, registered, objgraph, memsample, memdump, active_queues)\n\n\n",
        "hints_text": "what you get when you run celery inspect --help\nUsage: celery inspect [OPTIONS] [report|conf|query_task|clock|ping|stats|sched\r\n                      uled|reserved|active|revoked|registered|objgraph|memsamp\r\n                      le|memdump|active_queues]\r\n\r\n  Inspect the worker at runtime.\r\n\r\n  Availability: RabbitMQ (AMQP) and Redis transports.\r\n\r\nRemote Control Options:\r\n  -t, --timeout FLOAT             Timeout in seconds waiting for reply.\r\n  -d, --destination COMMA SEPARATED LIST\r\n                                  Comma separated list of destination node\r\n                                  names.\r\n\r\n  -j, --json                      Use json as output format.\r\n\r\nOptions:\r\n  --help  Show this message and exit.\nmay be @thedrow can share some insight\nI have a monitoring script that (among many things) uses inspection API and calls active_queues(). With Celery 5.1.2 the scripts fails to work with key error, as active_queues() returns nothing... 4.4.x works as expected...\nThe code I used to test is here: https://gitlab.com/dejan/ceex (here I keep all my CElery EXperiments). If you run `celery -A ceex.inspect_node_stats worker -l debug` and try to `celery -A ceex.inspect_node_stats inspect node_stats` with 5.1.2 you will see it does not work. Again, try with 4.4.7 - it does work.\nOops, thanks - I did not know it was created as private repo... It is open to public now.\nAny update on this?\nLooking the code of the control.py \r\n\r\n```\r\n@click.argument(\"action\", type=click.Choice([\r\n    name for name, info in Panel.meta.items()\r\n    if info.type == 'control' and info.visible\r\n]))\r\n```\r\n\r\nthis above decorator doesn't read the global Meta properly. I'm still trying to figure out why. \nI encountered this bug today. This bug is caused by the fact that `Panel.meta.items()` is evaluated when the `bin/control.py` file is imported. This happens _after_ the command definitions in `worker/control.py`, but _before_ any of my custom commands are defined. All the modules in `bin/` are imported when the `celery` command is run, so I don't see any quickfix or workaround.\r\n\r\nI guess you could move away from `click.Choice` and accept any string as the command name instead. We would then need to validate the given string manually \u2013 the user's Celery app will be set up by the time we reach the function body, so their custom commands will be registered by then. Maybe a new flag, e.g. `--list`, could print the available commands and exit.\r\n\r\nWould this be an acceptable solution? I may try to implement it if desired.\nThis bug is basically preventing us from moving to new(er) Celery as we have few critical inspect and control commands that we use all the time.\n> I encountered this bug today. This bug is caused by the fact that `Panel.meta.items()` is evaluated when the `bin/control.py` file is imported. This happens _after_ the command definitions in `worker/control.py`, but _before_ any of my custom commands are defined. All the modules in `bin/` are imported when the `celery` command is run, so I don't see any quickfix or workaround.\r\n> \r\n> I guess you could move away from `click.Choice` and accept any string as the command name instead. We would then need to validate the given string manually \u2013 the user's Celery app will be set up by the time we reach the function body, so their custom commands will be registered by then. Maybe a new flag, e.g. `--list`, could print the available commands and exit.\r\n> \r\n> Would this be an acceptable solution? I may try to implement it if desired.\r\n\r\nyou can come with a draft proof of concept PR with relevant test for review",
        "created_at": "2023-09-07T13:46:57Z",
        "version": "5.3",
        "PASS_TO_PASS": [],
        "FAIL_TO_PASS": [
            "t/unit/app/test_preload_cli.py"
        ]
    },
    {
        "repo": "celery/celery",
        "pull_number": 8486,
        "instance_id": "celery__celery-8486",
        "issue_numbers": [
            "7715",
            "8472"
        ],
        "base_commit": "14892abbb8cf80d7abcf41f4a48c049d84f69f74",
        "patch": "diff --git a/celery/app/task.py b/celery/app/task.py\nindex 7998d600b76..22d9a8ebd0c 100644\n--- a/celery/app/task.py\n+++ b/celery/app/task.py\n@@ -788,6 +788,7 @@ def apply(self, args=None, kwargs=None,\n \n         request = {\n             'id': task_id,\n+            'task': self.name,\n             'retries': retries,\n             'is_eager': True,\n             'logfile': logfile,\n@@ -824,7 +825,7 @@ def apply(self, args=None, kwargs=None,\n         if isinstance(retval, Retry) and retval.sig is not None:\n             return retval.sig.apply(retries=retries + 1)\n         state = states.SUCCESS if ret.info is None else ret.info.state\n-        return EagerResult(task_id, retval, state, traceback=tb)\n+        return EagerResult(task_id, retval, state, traceback=tb, name=self.name)\n \n     def AsyncResult(self, task_id, **kwargs):\n         \"\"\"Get AsyncResult instance for the specified task.\ndiff --git a/celery/result.py b/celery/result.py\nindex 0c9e0a30f21..c566a2573b7 100644\n--- a/celery/result.py\n+++ b/celery/result.py\n@@ -983,13 +983,14 @@ def restore(cls, id, backend=None, app=None):\n class EagerResult(AsyncResult):\n     \"\"\"Result that we know has already been executed.\"\"\"\n \n-    def __init__(self, id, ret_value, state, traceback=None):\n+    def __init__(self, id, ret_value, state, traceback=None, name=None):\n         # pylint: disable=super-init-not-called\n         # XXX should really not be inheriting from AsyncResult\n         self.id = id\n         self._result = ret_value\n         self._state = state\n         self._traceback = traceback\n+        self._name = name\n         self.on_ready = promise()\n         self.on_ready(self)\n \n@@ -1042,6 +1043,7 @@ def _cache(self):\n             'result': self._result,\n             'status': self._state,\n             'traceback': self._traceback,\n+            'name': self._name,\n         }\n \n     @property\n",
        "test_patch": "diff --git a/t/unit/tasks/test_result.py b/t/unit/tasks/test_result.py\nindex 42eaab8987d..30e0b9ef134 100644\n--- a/t/unit/tasks/test_result.py\n+++ b/t/unit/tasks/test_result.py\n@@ -967,6 +967,13 @@ def test_get_sync_subtask_option(self, task_join_will_block):\n             res_subtask_async.get()\n         res_subtask_async.get(disable_sync_subtasks=False)\n \n+    def test_populate_name(self):\n+        res = EagerResult('x', 'x', states.SUCCESS, None, 'test_task')\n+        assert res.name == 'test_task'\n+\n+        res = EagerResult('x', 'x', states.SUCCESS, name='test_task_named_argument')\n+        assert res.name == 'test_task_named_argument'\n+\n \n class test_tuples:\n \ndiff --git a/t/unit/tasks/test_tasks.py b/t/unit/tasks/test_tasks.py\nindex 36bb792b16d..5a0cd7c2f19 100644\n--- a/t/unit/tasks/test_tasks.py\n+++ b/t/unit/tasks/test_tasks.py\n@@ -1432,6 +1432,7 @@ def test_apply(self):\n \n         assert e.successful()\n         assert e.ready()\n+        assert e.name == 't.unit.tasks.test_tasks.increment_counter'\n         assert repr(e).startswith('<EagerResult:')\n \n         f = self.raising.apply()\n@@ -1441,6 +1442,21 @@ def test_apply(self):\n         with pytest.raises(KeyError):\n             f.get()\n \n+    def test_apply_eager_populates_request_task(self):\n+        task_to_apply = self.task_check_request_context\n+        with patch.object(\n+            task_to_apply.request_stack, \"push\",\n+            wraps=task_to_apply.request_stack.push,\n+        ) as mock_push:\n+            task_to_apply.apply()\n+\n+        mock_push.assert_called_once()\n+\n+        request = mock_push.call_args[0][0]\n+\n+        assert request.is_eager is True\n+        assert request.task == 't.unit.tasks.test_tasks.task_check_request_context'\n+\n     def test_apply_simulates_delivery_info(self):\n         task_to_apply = self.task_check_request_context\n         with patch.object(\n",
        "problem_statement": "EagerResult doesn't seem to poplate name\nSometimes I run my tasks with `CELERY_TASK_ALWAYS_EAGER` to aid debugging, it seems like the `name` property of EagerResult isn't populated, which makes this sort of investigation more tricky.\r\n\r\nI have some code I use to list my tasks in a django app, and part of this is to grab the task name.\r\n\r\nWhen running eagerly, the EagerResult task status is SUCCESS, so I would have expected `name` to be available at this point.\n5.3.2/3 has BREAKING change on EagerResult\n<!--\r\nPlease fill this template entirely and do not erase parts of it.\r\nWe reserve the right to close without a response\r\nbug reports which are incomplete.\r\n-->\r\n# Checklist\r\n<!--\r\nTo check an item on the list replace [ ] with [x].\r\n-->\r\n- [x] I have verified that the issue exists against the `main` branch of Celery.\r\n- [ ] This has already been asked to the [discussions forum](https://github.com/celery/celery/discussions) first.\r\n- [ ] I have read the relevant section in the\r\n  [contribution guide](https://docs.celeryq.dev/en/main/contributing.html#other-bugs)\r\n  on reporting bugs.\r\n- [x] I have checked the [issues list](https://github.com/celery/celery/issues?q=is%3Aissue+label%3A%22Issue+Type%3A+Bug+Report%22+-label%3A%22Category%3A+Documentation%22)\r\n  for similar or identical bug reports.\r\n- [x] I have checked the [pull requests list](https://github.com/celery/celery/pulls?q=is%3Apr+label%3A%22PR+Type%3A+Bugfix%22+-label%3A%22Category%3A+Documentation%22)\r\n  for existing proposed fixes.\r\n- [x] I have checked the [commit log](https://github.com/celery/celery/commits/main)\r\n  to find out if the bug was already fixed in the main branch.\r\n- [ ] I have included all related issues and possible duplicate issues\r\n  in this issue (If there are none, check this box anyway).\r\n\r\n## Mandatory Debugging Information\r\n\r\n- [ ] I have included the output of ``celery -A proj report`` in the issue.\r\n    (if you are not able to do this, then at least specify the Celery\r\n     version affected).\r\n- [x] I have verified that the issue exists against the `main` branch of Celery.\r\n- [ ] I have included the contents of ``pip freeze`` in the issue.\r\n- [ ] I have included all the versions of all the external dependencies required\r\n  to reproduce this bug.\r\n\r\n## Optional Debugging Information\r\n<!--\r\nTry some of the below if you think they are relevant.\r\nIt will help us figure out the scope of the bug and how many users it affects.\r\n-->\r\n- [ ] I have tried reproducing the issue on more than one Python version\r\n  and/or implementation.\r\n- [ ] I have tried reproducing the issue on more than one message broker and/or\r\n  result backend.\r\n- [ ] I have tried reproducing the issue on more than one version of the message\r\n  broker and/or result backend.\r\n- [ ] I have tried reproducing the issue on more than one operating system.\r\n- [ ] I have tried reproducing the issue on more than one workers pool.\r\n- [ ] I have tried reproducing the issue with autoscaling, retries,\r\n  ETA/Countdown & rate limits disabled.\r\n- [x] I have tried reproducing the issue after downgrading\r\n  and/or upgrading Celery and its dependencies.\r\n\r\n## Related Issues and Possible Duplicates\r\n<!--\r\nPlease make sure to search and mention any related issues\r\nor possible duplicates to this issue as requested by the checklist above.\r\n\r\nThis may or may not include issues in other repositories that the Celery project\r\nmaintains or other repositories that are dependencies of Celery.\r\n\r\nIf you don't know how to mention issues, please refer to Github's documentation\r\non the subject: https://help.github.com/en/articles/autolinked-references-and-urls#issues-and-pull-requests\r\n-->\r\n\r\n#### Related Issues\r\n\r\n- None\r\n\r\n#### Possible Duplicates\r\n\r\n- None\r\n\r\n## Environment & Settings\r\n<!-- Include the contents of celery --version below -->\r\n**Celery version**: 5.3.3\r\n<!-- Include the output of celery -A proj report below -->\r\n<details>\r\n<summary><b><code>celery report</code> Output:</b></summary>\r\n<p>\r\n\r\n```\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n# Steps to Reproduce\r\n\r\n## Required Dependencies\r\n<!-- Please fill the required dependencies to reproduce this issue -->\r\n- **Minimal Python Version**: N/A or Unknown\r\n- **Minimal Celery Version**: N/A or Unknown\r\n- **Minimal Kombu Version**: N/A or Unknown\r\n- **Minimal Broker Version**: N/A or Unknown\r\n- **Minimal Result Backend Version**: N/A or Unknown\r\n- **Minimal OS and/or Kernel Version**: N/A or Unknown\r\n- **Minimal Broker Client Version**: N/A or Unknown\r\n- **Minimal Result Backend Client Version**: N/A or Unknown\r\n\r\n### Python Packages\r\n<!-- Please fill the contents of pip freeze below -->\r\n<details>\r\n<summary><b><code>pip freeze</code> Output:</b></summary>\r\n<p>\r\n\r\n```\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n### Other Dependencies\r\n<!--\r\nPlease provide system dependencies, configuration files\r\nand other dependency information if applicable\r\n-->\r\n<details>\r\n<p>\r\nN/A\r\n</p>\r\n</details>\r\n\r\n## Minimally Reproducible Test Case\r\n<!--\r\nPlease provide a reproducible test case.\r\nRefer to the Reporting Bugs section in our contribution guide.\r\n\r\nWe prefer submitting test cases in the form of a PR to our integration test suite.\r\nIf you can provide one, please mention the PR number below.\r\nIf not, please attach the most minimal code example required to reproduce the issue below.\r\nIf the test case is too large, please include a link to a gist or a repository below.\r\n-->\r\n\r\n<details>\r\n<p>\r\n\r\n```python\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n# Expected Behavior\r\n<!-- Describe in detail what you expect to happen -->\r\na patch release to not have a breaking change\r\n\r\n# Actual Behavior\r\n<!--\r\nDescribe in detail what actually happened.\r\nPlease include a backtrace and surround it with triple backticks (```).\r\nIn addition, include the Celery daemon logs, the broker logs,\r\nthe result backend logs and system logs below if they will help us debug\r\nthe issue.\r\n-->\r\nhttps://github.com/celery/celery/commit/1c363876147325a196c474e757e355c451a0cdff#diff-05689f277021b9af9d8314849c9d938db0f5a42e932169a116463ef91ae9af78R986\r\n\r\n```\r\nTypeError\r\nEagerResult.__init__() missing 1 required positional argument: 'state'\r\n```\n",
        "hints_text": "Hey @stuaxo :wave:,\nThank you for opening an issue. We will get back to you as soon as we can.\nAlso, check out our [Open Collective](https://opencollective.com/celery) and consider backing us - every little helps!\n\nWe also offer priority support for our sponsors.\nIf you require immediate assistance please consider sponsoring us.\n\ndo you have any failing test/implementation detail in mind to share?\nI'll see what I can find, I'm no longer working at the organisation* I did that project for, but it is open source so I still have that work and can share it :)\r\n\r\n*I'm a contractor and move from place to place.\nBTW, I am a contractor too\nI really wish that every contract had a budget to put towards open source projects they use - I did raise this @ the last place, but probably not in the right places.\r\n\r\nThe furthest I've got is submitting patches to projects used.\n",
        "created_at": "2023-09-04T22:38:21Z",
        "version": "5.3",
        "PASS_TO_PASS": [],
        "FAIL_TO_PASS": [
            "t/unit/tasks/test_result.py",
            "t/unit/tasks/test_tasks.py"
        ]
    },
    {
        "repo": "celery/celery",
        "pull_number": 8462,
        "instance_id": "celery__celery-8462",
        "issue_numbers": [
            "8461"
        ],
        "base_commit": "8ae0b229596cc8aeea4fb71020d9358a59338e08",
        "patch": "diff --git a/celery/bin/celery.py b/celery/bin/celery.py\nindex 15558813b0b..4aeed42597f 100644\n--- a/celery/bin/celery.py\n+++ b/celery/bin/celery.py\n@@ -136,7 +136,8 @@ def convert(self, value, param, ctx):\n               cls=CeleryOption,\n               is_flag=True,\n               help_group=\"Global Options\",\n-              help=\"Skip Django core checks on startup.\")\n+              help=\"Skip Django core checks on startup. Setting the SKIP_CHECKS environment \"\n+                   \"variable to any non-empty string will have the same effect.\")\n @click.pass_context\n def celery(ctx, app, broker, result_backend, loader, config, workdir,\n            no_color, quiet, version, skip_checks):\n@@ -158,7 +159,7 @@ def celery(ctx, app, broker, result_backend, loader, config, workdir,\n     if config:\n         os.environ['CELERY_CONFIG_MODULE'] = config\n     if skip_checks:\n-        os.environ['CELERY_SKIP_CHECKS'] = skip_checks\n+        os.environ['CELERY_SKIP_CHECKS'] = 'true'\n     ctx.obj = CLIContext(app=app, no_color=no_color, workdir=workdir,\n                          quiet=quiet)\n \n",
        "test_patch": "diff --git a/t/unit/bin/test_worker.py b/t/unit/bin/test_worker.py\nindex 50a07e3b674..b63a2a03306 100644\n--- a/t/unit/bin/test_worker.py\n+++ b/t/unit/bin/test_worker.py\n@@ -1,3 +1,6 @@\n+import os\n+from unittest.mock import patch\n+\n import pytest\n from click.testing import CliRunner\n \n@@ -18,3 +21,15 @@ def test_cli(isolated_cli_runner: CliRunner):\n         catch_exceptions=False\n     )\n     assert res.exit_code == 1, (res, res.stdout)\n+\n+\n+def test_cli_skip_checks(isolated_cli_runner: CliRunner):\n+    Logging._setup = True  # To avoid hitting the logging sanity checks\n+    with patch.dict(os.environ, clear=True):\n+        res = isolated_cli_runner.invoke(\n+            celery,\n+            [\"-A\", \"t.unit.bin.proj.app\", \"--skip-checks\", \"worker\", \"--pool\", \"solo\"],\n+            catch_exceptions=False,\n+        )\n+        assert res.exit_code == 1, (res, res.stdout)\n+        assert os.environ[\"CELERY_SKIP_CHECKS\"] == \"true\", \"should set CELERY_SKIP_CHECKS\"\ndiff --git a/t/unit/fixups/test_django.py b/t/unit/fixups/test_django.py\nindex 07f94c6b813..8a97884ed4a 100644\n--- a/t/unit/fixups/test_django.py\n+++ b/t/unit/fixups/test_django.py\n@@ -272,7 +272,7 @@ def test_validate_models(self, patching, module):\n         f.django_setup.reset_mock()\n         run_checks.reset_mock()\n \n-        patching.setenv('CELERY_SKIP_CHECKS', True)\n+        patching.setenv('CELERY_SKIP_CHECKS', 'true')\n         f.validate_models()\n         f.django_setup.assert_called_with()\n         run_checks.assert_not_called()\n",
        "problem_statement": "Running worker with --skip-checks option fails with a TypeError\n<!--\r\nPlease fill this template entirely and do not erase parts of it.\r\nWe reserve the right to close without a response\r\nbug reports which are incomplete.\r\n-->\r\n# Checklist\r\n<!--\r\nTo check an item on the list replace [ ] with [x].\r\n-->\r\n- [x] I have verified that the issue exists against the `main` branch of Celery.\r\n- [ ] This has already been asked to the [discussions forum](https://github.com/celery/celery/discussions) first.\r\n- [x] I have read the relevant section in the\r\n  [contribution guide](https://docs.celeryq.dev/en/main/contributing.html#other-bugs)\r\n  on reporting bugs.\r\n- [x] I have checked the [issues list](https://github.com/celery/celery/issues?q=is%3Aissue+label%3A%22Issue+Type%3A+Bug+Report%22+-label%3A%22Category%3A+Documentation%22)\r\n  for similar or identical bug reports.\r\n- [x] I have checked the [pull requests list](https://github.com/celery/celery/pulls?q=is%3Apr+label%3A%22PR+Type%3A+Bugfix%22+-label%3A%22Category%3A+Documentation%22)\r\n  for existing proposed fixes.\r\n- [x] I have checked the [commit log](https://github.com/celery/celery/commits/main)\r\n  to find out if the bug was already fixed in the main branch.\r\n- [x] I have included all related issues and possible duplicate issues\r\n  in this issue (If there are none, check this box anyway).\r\n\r\n## Mandatory Debugging Information\r\n\r\n- [x] I have included the output of ``celery -A proj report`` in the issue.\r\n    (if you are not able to do this, then at least specify the Celery\r\n     version affected).\r\n- [x] I have verified that the issue exists against the `main` branch of Celery.\r\n- [x] I have included the contents of ``pip freeze`` in the issue.\r\n- [x] I have included all the versions of all the external dependencies required\r\n  to reproduce this bug.\r\n\r\n## Optional Debugging Information\r\n<!--\r\nTry some of the below if you think they are relevant.\r\nIt will help us figure out the scope of the bug and how many users it affects.\r\n-->\r\n- [x] I have tried reproducing the issue on more than one Python version\r\n  and/or implementation.\r\n- [ ] I have tried reproducing the issue on more than one message broker and/or\r\n  result backend.\r\n- [ ] I have tried reproducing the issue on more than one version of the message\r\n  broker and/or result backend.\r\n- [ ] I have tried reproducing the issue on more than one operating system.\r\n- [ ] I have tried reproducing the issue on more than one workers pool.\r\n- [ ] I have tried reproducing the issue with autoscaling, retries,\r\n  ETA/Countdown & rate limits disabled.\r\n- [ ] I have tried reproducing the issue after downgrading\r\n  and/or upgrading Celery and its dependencies.\r\n\r\n## Related Issues and Possible Duplicates\r\n<!--\r\nPlease make sure to search and mention any related issues\r\nor possible duplicates to this issue as requested by the checklist above.\r\n\r\nThis may or may not include issues in other repositories that the Celery project\r\nmaintains or other repositories that are dependencies of Celery.\r\n\r\nIf you don't know how to mention issues, please refer to Github's documentation\r\non the subject: https://help.github.com/en/articles/autolinked-references-and-urls#issues-and-pull-requests\r\n-->\r\n\r\n#### Related Issues\r\n\r\n- #7581 (feature request that led to the `--skip-checks` option being added)\r\n- #7859 (PR that added the option)\r\n\r\n#### Possible Duplicates\r\n\r\n- None\r\n\r\n## Environment & Settings\r\n<!-- Include the contents of celery --version below -->\r\n**Celery version**: 5.3.1 (emerald-rush)\r\n<!-- Include the output of celery -A proj report below -->\r\n<details>\r\n<summary><b><code>celery report</code> Output:</b></summary>\r\n<p>\r\n\r\nThis is on the Docker dev container. The results are not substantially different from the system on which I encountered the failure, aside from a massive and mostly irrelevant Django settings dump.\r\n\r\n```\r\ndeveloper@dc2346ef89d6:~/celery$ celery --config t.integration.test_worker_config report\r\n\r\nsoftware -> celery:5.3.1 (emerald-rush) kombu:5.3.1 py:3.8.18\r\n            billiard:4.1.0 py-amqp:5.1.1\r\nplatform -> system:Linux arch:64bit\r\n            kernel version:5.15.49-linuxkit-pr imp:CPython\r\nloader   -> celery.loaders.default.Loader\r\nsettings -> transport:amqp results:disabled\r\n\r\nbroker_connection_retry: False\r\nbroker_connection_retry_on_startup: False\r\nbroker_connection_timeout: 0\r\nbroker_url: 'amqp://guest:********@foobar:1234//'\r\nworker_log_color: False\r\nworker_redirect_stdouts: False\r\ndeprecated_settings: None\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n# Steps to Reproduce\r\n\r\nRun a worker with the `--skip-checks` option or with`CELERY_SKIP_CHECKS=1` (or any non-empty value) in the environment.\r\n\r\n## Required Dependencies\r\n<!-- Please fill the required dependencies to reproduce this issue -->\r\n- **Minimal Python Version**: N/A or Unknown\r\n- **Minimal Celery Version**: 5.3.1 (emerald-rush)\r\n- **Minimal Kombu Version**: N/A or Unknown\r\n- **Minimal Broker Version**: N/A or Unknown\r\n- **Minimal Result Backend Version**: N/A or Unknown\r\n- **Minimal OS and/or Kernel Version**: N/A or Unknown\r\n- **Minimal Broker Client Version**: N/A or Unknown\r\n- **Minimal Result Backend Client Version**: N/A or Unknown\r\n\r\n### Python Packages\r\n<!-- Please fill the contents of pip freeze below -->\r\n<details>\r\n<summary><b><code>pip freeze</code> Output:</b></summary>\r\n<p>\r\n\r\n```\r\nalabaster==0.7.13\r\namqp==5.1.1\r\nasync-timeout==4.0.3\r\nattrs==23.1.0\r\nazure-core==1.29.3\r\nazure-storage-blob==12.17.0\r\nBabel==2.12.1\r\nbackports.zoneinfo==0.2.1\r\nbilliard==4.1.0\r\nboto3==1.28.36\r\nbotocore==1.31.36\r\nbump2version==1.0.1\r\nbumpversion==0.6.0\r\ncachetools==5.3.1\r\ncassandra-driver==3.28.0\r\ncelery==5.3.1\r\ncertifi==2023.7.22\r\ncffi==1.15.1\r\ncfgv==3.4.0\r\nchardet==5.2.0\r\ncharset-normalizer==3.2.0\r\nclick==8.1.7\r\nclick-didyoumean==0.3.0\r\nclick-plugins==1.1.1\r\nclick-repl==0.3.0\r\ncolorama==0.4.6\r\ncouchbase==4.1.8\r\ncoverage==7.3.0\r\ncryptography==41.0.3\r\nDateTime==5.2\r\ndistlib==0.3.7\r\ndnspython==2.4.2\r\ndocutils==0.19\r\nelasticsearch==7.17.9\r\nephem==4.1.4\r\neventlet==0.33.3\r\nexceptiongroup==1.1.3\r\nfilelock==3.12.3\r\nflake8==6.1.0\r\nflake8-docstrings==1.7.0\r\nflakeplus==1.1.0\r\nfuture==0.18.3\r\ngeomet==0.2.1.post1\r\ngevent==23.7.0\r\ngreenlet==2.0.2\r\nidentify==2.5.27\r\nidna==3.4\r\nimagesize==1.4.1\r\nimportlib-metadata==6.8.0\r\niniconfig==2.0.0\r\nisodate==0.6.1\r\nisort==5.12.0\r\nJinja2==3.1.2\r\njmespath==1.0.1\r\nkombu==5.3.1\r\nlivereload==2.6.3\r\nMarkupSafe==2.1.3\r\nmccabe==0.7.0\r\nmock==5.1.0\r\nmoto==4.2.0\r\nmsgpack==1.0.5\r\nmypy==1.5.0\r\nmypy-extensions==1.0.0\r\nnodeenv==1.8.0\r\npackaging==23.1\r\nplatformdirs==3.10.0\r\npluggy==1.3.0\r\npre-commit==3.3.3\r\nprompt-toolkit==3.0.39\r\npyArango==2.0.2\r\npycodestyle==2.11.0\r\npycouchdb==1.14.2\r\npycparser==2.21\r\npycurl==7.45.2\r\npydocstyle==6.3.0\r\npydocumentdb==2.3.5\r\npyflakes==3.1.0\r\nPygments==2.16.1\r\npylibmc==1.6.3\r\npymongo==4.5.0\r\npyproject-api==1.5.4\r\npytest==7.4.0\r\npytest-celery==0.0.0\r\npytest-click==1.1.0\r\npytest-cov==4.1.0\r\npytest-github-actions-annotate-failures==0.2.0\r\npytest-order==1.1.0\r\npytest-rerunfailures==12.0\r\npytest-subtests==0.11.0\r\npytest-timeout==2.1.0\r\npython-consul2==0.1.5\r\npython-dateutil==2.8.2\r\npython-memcached==1.59\r\npytz==2023.3\r\nPyYAML==6.0.1\r\nredis==4.6.0\r\nrequests==2.31.0\r\nresponses==0.23.3\r\ns3transfer==0.6.2\r\nsix==1.16.0\r\nsnowballstemmer==2.2.0\r\nsoftlayer-messaging==1.0.3\r\nSphinx==5.3.0\r\nsphinx-autobuild==2021.3.14\r\nsphinx-celery==2.0.0\r\nsphinx-click==4.4.0\r\nsphinx-testing==1.0.1\r\nsphinx2rst==1.1.0\r\nsphinxcontrib-applehelp==1.0.4\r\nsphinxcontrib-devhelp==1.0.2\r\nsphinxcontrib-htmlhelp==2.0.1\r\nsphinxcontrib-jsmath==1.0.1\r\nsphinxcontrib-qthelp==1.0.3\r\nsphinxcontrib-serializinghtml==1.1.5\r\nSQLAlchemy==2.0.20\r\ntblib==2.0.0\r\ntomli==2.0.1\r\ntornado==6.3.3\r\ntox==4.10.0\r\ntypes-PyYAML==6.0.12.11\r\ntyping_extensions==4.7.1\r\ntzdata==2023.3\r\nUnipath==1.1\r\nurllib3==1.26.16\r\nvine==5.0.0\r\nvirtualenv==20.24.3\r\nwcwidth==0.2.6\r\nWerkzeug==2.3.7\r\nxmltodict==0.13.0\r\nzipp==3.16.2\r\nzope.event==5.0\r\nzope.interface==6.0\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n### Other Dependencies\r\n<!--\r\nPlease provide system dependencies, configuration files\r\nand other dependency information if applicable\r\n-->\r\n<details>\r\n<p>\r\nN/A\r\n</p>\r\n</details>\r\n\r\n## Minimally Reproducible Test Case\r\n<!--\r\nPlease provide a reproducible test case.\r\nRefer to the Reporting Bugs section in our contribution guide.\r\n\r\nWe prefer submitting test cases in the form of a PR to our integration test suite.\r\nIf you can provide one, please mention the PR number below.\r\nIf not, please attach the most minimal code example required to reproduce the issue below.\r\nIf the test case is too large, please include a link to a gist or a repository below.\r\n-->\r\n\r\n<details>\r\n<p>\r\nIn a shell opened with `docker compose run --rm celery bash`, the following illustrates the failure.\r\n\r\n```\r\ndeveloper@dc2346ef89d6:~/celery$ celery --skip-checks --config t.integration.test_worker_config report\r\nTraceback (most recent call last):\r\n  File \"/home/developer/.pyenv/versions/3.8.18/bin/celery\", line 8, in <module>\r\n    sys.exit(main())\r\n  File \"/home/developer/celery/celery/__main__.py\", line 15, in main\r\n    sys.exit(_main())\r\n  File \"/home/developer/celery/celery/bin/celery.py\", line 235, in main\r\n    return celery(auto_envvar_prefix=\"CELERY\")\r\n  File \"/home/developer/.pyenv/versions/3.8.18/lib/python3.8/site-packages/click/core.py\", line 1157, in __call__\r\n    return self.main(*args, **kwargs)\r\n  File \"/home/developer/.pyenv/versions/3.8.18/lib/python3.8/site-packages/click/core.py\", line 1078, in main\r\n    rv = self.invoke(ctx)\r\n  File \"/home/developer/.pyenv/versions/3.8.18/lib/python3.8/site-packages/click/core.py\", line 1685, in invoke\r\n    super().invoke(ctx)\r\n  File \"/home/developer/.pyenv/versions/3.8.18/lib/python3.8/site-packages/click/core.py\", line 1434, in invoke\r\n    return ctx.invoke(self.callback, **ctx.params)\r\n  File \"/home/developer/.pyenv/versions/3.8.18/lib/python3.8/site-packages/click/core.py\", line 783, in invoke\r\n    return __callback(*args, **kwargs)\r\n  File \"/home/developer/.pyenv/versions/3.8.18/lib/python3.8/site-packages/click/decorators.py\", line 33, in new_func\r\n    return f(get_current_context(), *args, **kwargs)\r\n  File \"/home/developer/celery/celery/bin/celery.py\", line 161, in celery\r\n    os.environ['CELERY_SKIP_CHECKS'] = skip_checks\r\n  File \"/home/developer/.pyenv/versions/3.8.18/lib/python3.8/os.py\", line 680, in __setitem__\r\n    value = self.encodevalue(value)\r\n  File \"/home/developer/.pyenv/versions/3.8.18/lib/python3.8/os.py\", line 750, in encode\r\n    raise TypeError(\"str expected, not %s\" % type(value).__name__)\r\nTypeError: str expected, not bool\r\n```\r\n\r\nAlternatively, for any non-empty value of `CELERY_SKIP_CHECKS`, same result:\r\n```\r\ndeveloper@dc2346ef89d6:~/celery$ CELERY_SKIP_CHECKS=1 celery --config t.integration.test_worker_config worker\r\nTraceback (most recent call last):\r\n  File \"/home/developer/.pyenv/versions/3.8.18/bin/celery\", line 8, in <module>\r\n    sys.exit(main())\r\n  File \"/home/developer/celery/celery/__main__.py\", line 15, in main\r\n    sys.exit(_main())\r\n  File \"/home/developer/celery/celery/bin/celery.py\", line 235, in main\r\n    return celery(auto_envvar_prefix=\"CELERY\")\r\n  File \"/home/developer/.pyenv/versions/3.8.18/lib/python3.8/site-packages/click/core.py\", line 1157, in __call__\r\n    return self.main(*args, **kwargs)\r\n  File \"/home/developer/.pyenv/versions/3.8.18/lib/python3.8/site-packages/click/core.py\", line 1078, in main\r\n    rv = self.invoke(ctx)\r\n  File \"/home/developer/.pyenv/versions/3.8.18/lib/python3.8/site-packages/click/core.py\", line 1685, in invoke\r\n    super().invoke(ctx)\r\n  File \"/home/developer/.pyenv/versions/3.8.18/lib/python3.8/site-packages/click/core.py\", line 1434, in invoke\r\n    return ctx.invoke(self.callback, **ctx.params)\r\n  File \"/home/developer/.pyenv/versions/3.8.18/lib/python3.8/site-packages/click/core.py\", line 783, in invoke\r\n    return __callback(*args, **kwargs)\r\n  File \"/home/developer/.pyenv/versions/3.8.18/lib/python3.8/site-packages/click/decorators.py\", line 33, in new_func\r\n    return f(get_current_context(), *args, **kwargs)\r\n  File \"/home/developer/celery/celery/bin/celery.py\", line 161, in celery\r\n    os.environ['CELERY_SKIP_CHECKS'] = skip_checks\r\n  File \"/home/developer/.pyenv/versions/3.8.18/lib/python3.8/os.py\", line 680, in __setitem__\r\n    value = self.encodevalue(value)\r\n  File \"/home/developer/.pyenv/versions/3.8.18/lib/python3.8/os.py\", line 750, in encode\r\n    raise TypeError(\"str expected, not %s\" % type(value).__name__)\r\nTypeError: str expected, not bool\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n# Expected Behavior\r\n<!-- Describe in detail what you expect to happen -->\r\nExpected either the `CELERY_SKIP_CHECKS=1` or the `--skip-checks` option to start up the celery worker with Django's initial checks disabled. In the context of the minimal test case, Celery should start up, show its welcome message, then exit with error due to inability to contact the message broker.\r\n\r\n# Actual Behavior\r\n<!--\r\nDescribe in detail what actually happened.\r\nPlease include a backtrace and surround it with triple backticks (```).\r\nIn addition, include the Celery daemon logs, the broker logs,\r\nthe result backend logs and system logs below if they will help us debug\r\nthe issue.\r\n-->\r\nCelery immediately exits with a `TypeError`. See the minimally reproducible test case section for backtraces.\n",
        "hints_text": "",
        "created_at": "2023-08-29T14:07:40Z",
        "version": "5.3",
        "PASS_TO_PASS": [],
        "FAIL_TO_PASS": [
            "t/unit/bin/test_worker.py",
            "t/unit/fixups/test_django.py"
        ]
    },
    {
        "repo": "celery/celery",
        "pull_number": 8432,
        "instance_id": "celery__celery-8432",
        "issue_numbers": [
            "8431",
            "8431"
        ],
        "base_commit": "7b4c4c3938385a994c346f6fa80ce87f4efc0001",
        "patch": "diff --git a/celery/backends/mongodb.py b/celery/backends/mongodb.py\nindex 654ca3710c9..c64fe380807 100644\n--- a/celery/backends/mongodb.py\n+++ b/celery/backends/mongodb.py\n@@ -182,7 +182,8 @@ def _store_result(self, task_id, result, state,\n                       traceback=None, request=None, **kwargs):\n         \"\"\"Store return value and state of an executed task.\"\"\"\n         meta = self._get_result_meta(result=self.encode(result), state=state,\n-                                     traceback=traceback, request=request)\n+                                     traceback=traceback, request=request,\n+                                     format_date=False)\n         # Add the _id for mongodb\n         meta['_id'] = task_id\n \n",
        "test_patch": "diff --git a/t/unit/backends/test_base.py b/t/unit/backends/test_base.py\nindex 1a355d3c3ef..f2ede1503e2 100644\n--- a/t/unit/backends/test_base.py\n+++ b/t/unit/backends/test_base.py\n@@ -176,6 +176,30 @@ def test_get_result_meta_with_none(self):\n         assert meta['kwargs'] == kwargs\n         assert meta['queue'] == 'celery'\n \n+    def test_get_result_meta_format_date(self):\n+        import datetime\n+        self.app.conf.result_extended = True\n+        b1 = BaseBackend(self.app)\n+        args = ['a', 'b']\n+        kwargs = {'foo': 'bar'}\n+\n+        request = Context(args=args, kwargs=kwargs)\n+        meta = b1._get_result_meta(result={'fizz': 'buzz'},\n+                                   state=states.SUCCESS, traceback=None,\n+                                   request=request, format_date=True)\n+        assert isinstance(meta['date_done'], str)\n+\n+        self.app.conf.result_extended = True\n+        b2 = BaseBackend(self.app)\n+        args = ['a', 'b']\n+        kwargs = {'foo': 'bar'}\n+\n+        request = Context(args=args, kwargs=kwargs)\n+        meta = b2._get_result_meta(result={'fizz': 'buzz'},\n+                                   state=states.SUCCESS, traceback=None,\n+                                   request=request, format_date=False)\n+        assert isinstance(meta['date_done'], datetime.datetime)\n+\n \n class test_BaseBackend_interface:\n \n",
        "problem_statement": "Invalid format of 'date_done' field in celery.task_results with backend mongodb\n<!--\r\nPlease fill this template entirely and do not erase parts of it.\r\nWe reserve the right to close without a response\r\nbug reports which are incomplete.\r\n-->\r\n# Checklist\r\n<!--\r\nTo check an item on the list replace [ ] with [x].\r\n-->\r\n- [x] I have verified that the issue exists against the `main` branch of Celery.\r\n- [ ] This has already been asked to the [discussions forum](https://github.com/celery/celery/discussions) first.\r\n- [x] I have read the relevant section in the\r\n  [contribution guide](https://docs.celeryq.dev/en/main/contributing.html#other-bugs)\r\n  on reporting bugs.\r\n- [x] I have checked the [issues list](https://github.com/celery/celery/issues?q=is%3Aissue+label%3A%22Issue+Type%3A+Bug+Report%22+-label%3A%22Category%3A+Documentation%22)\r\n  for similar or identical bug reports.\r\n- [x] I have checked the [pull requests list](https://github.com/celery/celery/pulls?q=is%3Apr+label%3A%22PR+Type%3A+Bugfix%22+-label%3A%22Category%3A+Documentation%22)\r\n  for existing proposed fixes.\r\n- [x] I have checked the [commit log](https://github.com/celery/celery/commits/main)\r\n  to find out if the bug was already fixed in the main branch.\r\n- [x] I have included all related issues and possible duplicate issues\r\n  in this issue (If there are none, check this box anyway).\r\n\r\n## Mandatory Debugging Information\r\n\r\n- [x] I have included the output of ``celery -A proj report`` in the issue.\r\n    (if you are not able to do this, then at least specify the Celery\r\n     version affected).\r\n- [x] I have verified that the issue exists against the `main` branch of Celery.\r\n- [x] I have included the contents of ``pip freeze`` in the issue.\r\n- [x] I have included all the versions of all the external dependencies required\r\n  to reproduce this bug.\r\n\r\n## Environment & Settings\r\n<!-- Include the contents of celery --version below -->\r\n**Celery version**: 5.3.1\r\n<!-- Include the output of celery -A proj report below -->\r\n<details>\r\n<summary><b><code>celery -A test_celery_result report</code> Output:</b></summary>\r\n<p>\r\n\r\n```\r\nsoftware -> celery:5.3.1 (emerald-rush) kombu:5.3.1 py:3.8.16\r\n            billiard:4.1.0 redis:4.6.0\r\nplatform -> system:Linux arch:64bit, ELF\r\n            kernel version:5.19.0-46-generic imp:CPython\r\nloader   -> celery.loaders.app.AppLoader\r\nsettings -> transport:redis results:mongodb\r\n[...]\r\nCELERY_BROKER_TRANSPORT_OPTIONS: \r\n 'socket_keepalive': True, 'socket_keepalive_options': {4: 600, 5: 60, 6: 5}}\r\nCELERY_BROKER_URL: 'redis://redis.local:7000/0'\r\nCELERY_INCLUDE: ['test_celery_result.tasks']\r\nCELERY_QUEUE_NAME: 'test_celery_result'\r\nCELERY_REDIS: \r\n 'host': 'redis.local', 'port': 7000}\r\n[...]\r\nis_overridden: <bound method Settings.is_overridden of <Settings \"test_celery_result.settings\">>\r\ndeprecated_settings: None\r\ntask_default_queue: 'test_celery_result'\r\nenable_utc: False\r\nresult_backend: 'mongodb'\r\nresult_expires: datetime.timedelta(seconds=15)\r\nmongodb_backend_settings: \r\n    'database': '********',\r\n    'host': ['mongo-replica'],\r\n    'port': 27017,\r\n    'taskmeta_collection': 'celery_task_result'}\r\nbeat_schedule: \r\n    'celery.backend_cleanup': {   'schedule': 60,\r\n                                  'task': 'celery.backend_cleanup'},\r\n    'dummy_task': {'schedule': 15, 'task': 'dummy_task'}}\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n# Steps to Reproduce\r\n\r\n## Required Dependencies\r\n<!-- Please fill the required dependencies to reproduce this issue -->\r\n- **Minimal Python Version**: 3.6 or higher\r\n- **Minimal Celery Version**: 4.3.0 or higher\r\n- **Minimal Kombu Version**: Unknown\r\n- **Minimal Broker Version**: Unknown\r\n- **Minimal Result Backend Version**: Mongo 4.4 or higher\r\n- **Minimal OS and/or Kernel Version**: Unknown\r\n- **Minimal Broker Client Version**: Unknown\r\n- **Minimal Result Backend Client Version**: pymongo 3.14 or higher\r\n\r\n### Python Packages\r\n<!-- Please fill the contents of pip freeze below -->\r\n<details>\r\n<summary><b><code>pip freeze</code> Output:</b></summary>\r\n<p>\r\n\r\namqp==5.1.1\r\nasgiref==3.7.2\r\nasync-timeout==4.0.2\r\nbackports.zoneinfo==0.2.1\r\nbilliard==4.1.0\r\nbleach==6.0.0\r\ncelery==5.3.1\r\ncertifi==2023.7.22\r\ncffi==1.15.1\r\ncharset-normalizer==3.2.0\r\nclick==8.1.6\r\nclick-didyoumean==0.3.0\r\nclick-plugins==1.1.1\r\nclick-repl==0.3.0\r\ncryptography==41.0.3\r\nDjango==3.2.20\r\ndjango-cors-headers==4.2.0\r\ndjango-environ==0.10.0\r\ndjango-formset-js==0.5.0\r\ndjango-jquery-js==3.1.1\r\ndjango-redis-sessions==0.6.2\r\ndjango-test-addons-adv==1.1.1\r\ndnspython==2.4.1\r\nidna==3.4\r\nJinja2==3.1.2\r\nkombu==5.3.1\r\npackaging==23.1\r\nprompt-toolkit==3.0.39\r\npyasn1==0.5.0\r\npycparser==2.21\r\npyhcl==0.4.4\r\npymongo==4.4.1\r\npython-dateutil==2.8.2\r\npytz==2022.1\r\nPyYAML==6.0.1\r\nredis==4.6.0\r\nrequests==2.31.0\r\nsentinels==1.0.0\r\nsingle-beat==0.6.3\r\nsix==1.16.0\r\nsqlparse==0.4.4\r\ntypes-PyYAML==6.0.12.11\r\ntyping_extensions==4.7.1\r\ntzdata==2023.3\r\nurllib3==1.26.16\r\nvine==5.0.0\r\nwcwidth==0.2.6\r\nwebencodings==0.5.1\r\n\r\n</p>\r\n</details>\r\n\r\n## Minimally Reproducible Test Case\r\n<!--\r\nPlease provide a reproducible test case.\r\nRefer to the Reporting Bugs section in our contribution guide.\r\n\r\nWe prefer submitting test cases in the form of a PR to our integration test suite.\r\nIf you can provide one, please mention the PR number below.\r\nIf not, please attach the most minimal code example required to reproduce the issue below.\r\nIf the test case is too large, please include a link to a gist or a repository below.\r\n-->\r\n\r\n<details>\r\n<p>\r\n<ul> \r\n<li>1. Set up a celery project with mongodb as backend</li>\r\n<li>2. Set <pre>app.conf.result_expires = timedelta(seconds=60)</pre></li>\r\n<li>2. Set up a scheduled task <pre>app.conf.beat_schedule = {\r\n    \"dummy_task\": {\r\n        \"task\": \"dummy_task\",\r\n        \"schedule\": 15\r\n    },\r\n}</pre></li>\r\n<li>3. Start celery worker and celery beat</li>\r\n<li>4. Open shell on mongodb backend and see that db.task_result.count() never resets to 0</li>\r\n</ul> \r\n</p>\r\n</details>\r\n\r\n# Expected Behavior\r\n`task_result` collection on mongo database shoud be cleaned every 60s according to `result_expires` configuration\r\n\r\n# Actual Behavior\r\n<!--\r\nDescribe in detail what actually happened.\r\nPlease include a backtrace and surround it with triple backticks (```).\r\nIn addition, include the Celery daemon logs, the broker logs,\r\nthe result backend logs and system logs below if they will help us debug\r\nthe issue.\r\n-->\r\n\r\nThere is an issue with the format of field `date_done` in task_result collection. Task results meta are retrieved with the method `_get_result_meta` from `base.py` which argument `format_date` is set to `True` by default. `date_done` field will be converted from `datetime` object to `str` and then inserted as a string in mongodb database.\r\n\r\nAnd so when `cleanup()` method is called on `MongoBackend`, it will compare `date_done` field with datetime object from `self.app.now()` and will never match.\r\n\r\n```python\r\nself.collection.delete_many(\r\n        {'date_done': {'$lt': self.app.now() - self.expires_delta}},\r\n    )\r\n# self.app.now() return datetime object while date_done is stored as string\r\n```\r\n\r\n```\r\n> db.task_result.findOne()\r\n{\r\n        \"_id\" : \"f16bd459-b858-4ae8-afb5-1ceab0e50326\",\r\n        \"status\" : \"SUCCESS\",\r\n        \"result\" : \"\\\"SUCCESS\\\"\",\r\n        \"traceback\" : null,\r\n        \"children\" : [ ],\r\n        \"date_done\" : \"2023-08-08T09:03:34.974924\" // should be ISODate(\"2023-08-08T09:03:34.9749Z\")\r\n}\r\n```\r\n\r\nA simple fix would be to set `format_date` to `False` when calling `self.get_result_meta` in `MongoBackend._strore_result`\nInvalid format of 'date_done' field in celery.task_results with backend mongodb\n<!--\r\nPlease fill this template entirely and do not erase parts of it.\r\nWe reserve the right to close without a response\r\nbug reports which are incomplete.\r\n-->\r\n# Checklist\r\n<!--\r\nTo check an item on the list replace [ ] with [x].\r\n-->\r\n- [x] I have verified that the issue exists against the `main` branch of Celery.\r\n- [ ] This has already been asked to the [discussions forum](https://github.com/celery/celery/discussions) first.\r\n- [x] I have read the relevant section in the\r\n  [contribution guide](https://docs.celeryq.dev/en/main/contributing.html#other-bugs)\r\n  on reporting bugs.\r\n- [x] I have checked the [issues list](https://github.com/celery/celery/issues?q=is%3Aissue+label%3A%22Issue+Type%3A+Bug+Report%22+-label%3A%22Category%3A+Documentation%22)\r\n  for similar or identical bug reports.\r\n- [x] I have checked the [pull requests list](https://github.com/celery/celery/pulls?q=is%3Apr+label%3A%22PR+Type%3A+Bugfix%22+-label%3A%22Category%3A+Documentation%22)\r\n  for existing proposed fixes.\r\n- [x] I have checked the [commit log](https://github.com/celery/celery/commits/main)\r\n  to find out if the bug was already fixed in the main branch.\r\n- [x] I have included all related issues and possible duplicate issues\r\n  in this issue (If there are none, check this box anyway).\r\n\r\n## Mandatory Debugging Information\r\n\r\n- [x] I have included the output of ``celery -A proj report`` in the issue.\r\n    (if you are not able to do this, then at least specify the Celery\r\n     version affected).\r\n- [x] I have verified that the issue exists against the `main` branch of Celery.\r\n- [x] I have included the contents of ``pip freeze`` in the issue.\r\n- [x] I have included all the versions of all the external dependencies required\r\n  to reproduce this bug.\r\n\r\n## Environment & Settings\r\n<!-- Include the contents of celery --version below -->\r\n**Celery version**: 5.3.1\r\n<!-- Include the output of celery -A proj report below -->\r\n<details>\r\n<summary><b><code>celery -A test_celery_result report</code> Output:</b></summary>\r\n<p>\r\n\r\n```\r\nsoftware -> celery:5.3.1 (emerald-rush) kombu:5.3.1 py:3.8.16\r\n            billiard:4.1.0 redis:4.6.0\r\nplatform -> system:Linux arch:64bit, ELF\r\n            kernel version:5.19.0-46-generic imp:CPython\r\nloader   -> celery.loaders.app.AppLoader\r\nsettings -> transport:redis results:mongodb\r\n[...]\r\nCELERY_BROKER_TRANSPORT_OPTIONS: \r\n 'socket_keepalive': True, 'socket_keepalive_options': {4: 600, 5: 60, 6: 5}}\r\nCELERY_BROKER_URL: 'redis://redis.local:7000/0'\r\nCELERY_INCLUDE: ['test_celery_result.tasks']\r\nCELERY_QUEUE_NAME: 'test_celery_result'\r\nCELERY_REDIS: \r\n 'host': 'redis.local', 'port': 7000}\r\n[...]\r\nis_overridden: <bound method Settings.is_overridden of <Settings \"test_celery_result.settings\">>\r\ndeprecated_settings: None\r\ntask_default_queue: 'test_celery_result'\r\nenable_utc: False\r\nresult_backend: 'mongodb'\r\nresult_expires: datetime.timedelta(seconds=15)\r\nmongodb_backend_settings: \r\n    'database': '********',\r\n    'host': ['mongo-replica'],\r\n    'port': 27017,\r\n    'taskmeta_collection': 'celery_task_result'}\r\nbeat_schedule: \r\n    'celery.backend_cleanup': {   'schedule': 60,\r\n                                  'task': 'celery.backend_cleanup'},\r\n    'dummy_task': {'schedule': 15, 'task': 'dummy_task'}}\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n# Steps to Reproduce\r\n\r\n## Required Dependencies\r\n<!-- Please fill the required dependencies to reproduce this issue -->\r\n- **Minimal Python Version**: 3.6 or higher\r\n- **Minimal Celery Version**: 4.3.0 or higher\r\n- **Minimal Kombu Version**: Unknown\r\n- **Minimal Broker Version**: Unknown\r\n- **Minimal Result Backend Version**: Mongo 4.4 or higher\r\n- **Minimal OS and/or Kernel Version**: Unknown\r\n- **Minimal Broker Client Version**: Unknown\r\n- **Minimal Result Backend Client Version**: pymongo 3.14 or higher\r\n\r\n### Python Packages\r\n<!-- Please fill the contents of pip freeze below -->\r\n<details>\r\n<summary><b><code>pip freeze</code> Output:</b></summary>\r\n<p>\r\n\r\namqp==5.1.1\r\nasgiref==3.7.2\r\nasync-timeout==4.0.2\r\nbackports.zoneinfo==0.2.1\r\nbilliard==4.1.0\r\nbleach==6.0.0\r\ncelery==5.3.1\r\ncertifi==2023.7.22\r\ncffi==1.15.1\r\ncharset-normalizer==3.2.0\r\nclick==8.1.6\r\nclick-didyoumean==0.3.0\r\nclick-plugins==1.1.1\r\nclick-repl==0.3.0\r\ncryptography==41.0.3\r\nDjango==3.2.20\r\ndjango-cors-headers==4.2.0\r\ndjango-environ==0.10.0\r\ndjango-formset-js==0.5.0\r\ndjango-jquery-js==3.1.1\r\ndjango-redis-sessions==0.6.2\r\ndjango-test-addons-adv==1.1.1\r\ndnspython==2.4.1\r\nidna==3.4\r\nJinja2==3.1.2\r\nkombu==5.3.1\r\npackaging==23.1\r\nprompt-toolkit==3.0.39\r\npyasn1==0.5.0\r\npycparser==2.21\r\npyhcl==0.4.4\r\npymongo==4.4.1\r\npython-dateutil==2.8.2\r\npytz==2022.1\r\nPyYAML==6.0.1\r\nredis==4.6.0\r\nrequests==2.31.0\r\nsentinels==1.0.0\r\nsingle-beat==0.6.3\r\nsix==1.16.0\r\nsqlparse==0.4.4\r\ntypes-PyYAML==6.0.12.11\r\ntyping_extensions==4.7.1\r\ntzdata==2023.3\r\nurllib3==1.26.16\r\nvine==5.0.0\r\nwcwidth==0.2.6\r\nwebencodings==0.5.1\r\n\r\n</p>\r\n</details>\r\n\r\n## Minimally Reproducible Test Case\r\n<!--\r\nPlease provide a reproducible test case.\r\nRefer to the Reporting Bugs section in our contribution guide.\r\n\r\nWe prefer submitting test cases in the form of a PR to our integration test suite.\r\nIf you can provide one, please mention the PR number below.\r\nIf not, please attach the most minimal code example required to reproduce the issue below.\r\nIf the test case is too large, please include a link to a gist or a repository below.\r\n-->\r\n\r\n<details>\r\n<p>\r\n<ul> \r\n<li>1. Set up a celery project with mongodb as backend</li>\r\n<li>2. Set <pre>app.conf.result_expires = timedelta(seconds=60)</pre></li>\r\n<li>2. Set up a scheduled task <pre>app.conf.beat_schedule = {\r\n    \"dummy_task\": {\r\n        \"task\": \"dummy_task\",\r\n        \"schedule\": 15\r\n    },\r\n}</pre></li>\r\n<li>3. Start celery worker and celery beat</li>\r\n<li>4. Open shell on mongodb backend and see that db.task_result.count() never resets to 0</li>\r\n</ul> \r\n</p>\r\n</details>\r\n\r\n# Expected Behavior\r\n`task_result` collection on mongo database shoud be cleaned every 60s according to `result_expires` configuration\r\n\r\n# Actual Behavior\r\n<!--\r\nDescribe in detail what actually happened.\r\nPlease include a backtrace and surround it with triple backticks (```).\r\nIn addition, include the Celery daemon logs, the broker logs,\r\nthe result backend logs and system logs below if they will help us debug\r\nthe issue.\r\n-->\r\n\r\nThere is an issue with the format of field `date_done` in task_result collection. Task results meta are retrieved with the method `_get_result_meta` from `base.py` which argument `format_date` is set to `True` by default. `date_done` field will be converted from `datetime` object to `str` and then inserted as a string in mongodb database.\r\n\r\nAnd so when `cleanup()` method is called on `MongoBackend`, it will compare `date_done` field with datetime object from `self.app.now()` and will never match.\r\n\r\n```python\r\nself.collection.delete_many(\r\n        {'date_done': {'$lt': self.app.now() - self.expires_delta}},\r\n    )\r\n# self.app.now() return datetime object while date_done is stored as string\r\n```\r\n\r\n```\r\n> db.task_result.findOne()\r\n{\r\n        \"_id\" : \"f16bd459-b858-4ae8-afb5-1ceab0e50326\",\r\n        \"status\" : \"SUCCESS\",\r\n        \"result\" : \"\\\"SUCCESS\\\"\",\r\n        \"traceback\" : null,\r\n        \"children\" : [ ],\r\n        \"date_done\" : \"2023-08-08T09:03:34.974924\" // should be ISODate(\"2023-08-08T09:03:34.9749Z\")\r\n}\r\n```\r\n\r\nA simple fix would be to set `format_date` to `False` when calling `self.get_result_meta` in `MongoBackend._strore_result`\n",
        "hints_text": "\n",
        "created_at": "2023-08-10T14:27:37Z",
        "version": "5.3",
        "PASS_TO_PASS": [],
        "FAIL_TO_PASS": [
            "t/unit/backends/test_base.py"
        ]
    },
    {
        "repo": "celery/celery",
        "pull_number": 8374,
        "instance_id": "celery__celery-8374",
        "issue_numbers": [
            "8259"
        ],
        "base_commit": "811ed96edbf7d7ae0681ae67ced63e6994a6e63a",
        "patch": "diff --git a/celery/bin/purge.py b/celery/bin/purge.py\nindex 7be1a8241fb..cfb6caa9323 100644\n--- a/celery/bin/purge.py\n+++ b/celery/bin/purge.py\n@@ -5,7 +5,9 @@\n from celery.utils import text\n \n \n-@click.command(cls=CeleryCommand)\n+@click.command(cls=CeleryCommand, context_settings={\n+    'allow_extra_args': True\n+})\n @click.option('-f',\n               '--force',\n               cls=CeleryOption,\n@@ -26,7 +28,7 @@\n               help=\"Comma separated list of queues names not to purge.\")\n @click.pass_context\n @handle_preload_options\n-def purge(ctx, force, queues, exclude_queues):\n+def purge(ctx, force, queues, exclude_queues, **kwargs):\n     \"\"\"Erase all messages from all known task queues.\n \n     Warning:\ndiff --git a/celery/bin/shell.py b/celery/bin/shell.py\nindex 77b14d8a307..6c94a00870e 100644\n--- a/celery/bin/shell.py\n+++ b/celery/bin/shell.py\n@@ -79,7 +79,9 @@ def _invoke_default_shell(locals):\n         _invoke_ipython_shell(locals)\n \n \n-@click.command(cls=CeleryCommand)\n+@click.command(cls=CeleryCommand, context_settings={\n+    'allow_extra_args': True\n+})\n @click.option('-I',\n               '--ipython',\n               is_flag=True,\n@@ -117,7 +119,7 @@ def _invoke_default_shell(locals):\n @handle_preload_options\n def shell(ctx, ipython=False, bpython=False,\n           python=False, without_tasks=False, eventlet=False,\n-          gevent=False):\n+          gevent=False, **kwargs):\n     \"\"\"Start shell session with convenient access to celery symbols.\n \n     The following symbols will be added to the main globals:\ndiff --git a/t/unit/bin/proj/pyramid_celery_app.py b/t/unit/bin/proj/pyramid_celery_app.py\nnew file mode 100644\nindex 00000000000..4878f95551b\n--- /dev/null\n+++ b/t/unit/bin/proj/pyramid_celery_app.py\n@@ -0,0 +1,53 @@\n+from unittest.mock import MagicMock, Mock\n+\n+from click import Option\n+\n+from celery import Celery\n+\n+# This module defines a mocked Celery application to replicate\n+# the behavior of Pyramid-Celery's configuration by preload options.\n+# Preload options should propagate to commands like shell and purge etc.\n+#\n+# The Pyramid-Celery project https://github.com/sontek/pyramid_celery\n+# assumes that you want to configure Celery via an ini settings file.\n+# The .ini files are the standard configuration file for Pyramid\n+# applications.\n+# See https://docs.pylonsproject.org/projects/pyramid/en/latest/quick_tutorial/ini.html\n+#\n+\n+app = Celery(set_as_current=False)\n+app.config_from_object(\"t.integration.test_worker_config\")\n+\n+\n+class PurgeMock:\n+    def queue_purge(self, queue):\n+        return 0\n+\n+\n+class ConnMock:\n+    default_channel = PurgeMock()\n+    channel_errors = KeyError\n+\n+\n+mock = Mock()\n+mock.__enter__ = Mock(return_value=ConnMock())\n+mock.__exit__ = Mock(return_value=False)\n+\n+app.connection_for_write = MagicMock(return_value=mock)\n+\n+# Below are taken from pyramid-celery's __init__.py\n+# Ref: https://github.com/sontek/pyramid_celery/blob/cf8aa80980e42f7235ad361874d3c35e19963b60/pyramid_celery/__init__.py#L25-L36 # noqa: E501\n+ini_option = Option(\n+    (\n+        \"--ini\",\n+        \"-i\",\n+    ),\n+    help=\"Paste ini configuration file.\",\n+)\n+\n+ini_var_option = Option(\n+    (\"--ini-var\",), help=\"Comma separated list of key=value to pass to ini.\"\n+)\n+\n+app.user_options[\"preload\"].add(ini_option)\n+app.user_options[\"preload\"].add(ini_var_option)\n",
        "test_patch": "diff --git a/t/unit/app/test_preload_cli.py b/t/unit/app/test_preload_cli.py\nnew file mode 100644\nindex 00000000000..a2241a1400d\n--- /dev/null\n+++ b/t/unit/app/test_preload_cli.py\n@@ -0,0 +1,63 @@\n+from click.testing import CliRunner\n+\n+from celery.bin.celery import celery\n+\n+\n+def test_preload_options(isolated_cli_runner: CliRunner):\n+    # Verify commands like shell and purge can accept preload options.\n+    # Projects like Pyramid-Celery's ini option should be valid preload\n+    # options.\n+\n+    # TODO: Find a way to run these separate invoke and assertions\n+    # such that order does not matter. Currently, running\n+    # the \"t.unit.bin.proj.pyramid_celery_app\" first seems\n+    # to result in cache or memoization of the option.\n+    # As a result, the expected exception is not raised when\n+    # the invoke on \"t.unit.bin.proj.app\" is run as a second\n+    # call.\n+\n+    res_without_preload = isolated_cli_runner.invoke(\n+        celery,\n+        [\"-A\", \"t.unit.bin.proj.app\", \"purge\", \"-f\", \"--ini\", \"some_ini.ini\"],\n+        catch_exceptions=True,\n+    )\n+\n+    assert \"No such option: --ini\" in res_without_preload.stdout\n+    assert res_without_preload.exit_code == 2\n+\n+    res_without_preload = isolated_cli_runner.invoke(\n+        celery,\n+        [\"-A\", \"t.unit.bin.proj.app\", \"shell\", \"--ini\", \"some_ini.ini\"],\n+        catch_exceptions=True,\n+    )\n+\n+    assert \"No such option: --ini\" in res_without_preload.stdout\n+    assert res_without_preload.exit_code == 2\n+\n+    res_with_preload = isolated_cli_runner.invoke(\n+        celery,\n+        [\n+            \"-A\",\n+            \"t.unit.bin.proj.pyramid_celery_app\",\n+            \"purge\",\n+            \"-f\",\n+            \"--ini\",\n+            \"some_ini.ini\",\n+        ],\n+        catch_exceptions=True,\n+    )\n+\n+    assert res_with_preload.exit_code == 0\n+\n+    res_with_preload = isolated_cli_runner.invoke(\n+        celery,\n+        [\n+            \"-A\",\n+            \"t.unit.bin.proj.pyramid_celery_app\",\n+            \"shell\",\n+            \"--ini\",\n+            \"some_ini.ini\",\n+        ],\n+        catch_exceptions=True,\n+    )\n+    assert res_with_preload.exit_code == 0\n",
        "problem_statement": "Set allow_extra_args to True in context_settings of shell and purge commands\n<!--\r\nPlease fill this template entirely and do not erase parts of it.\r\nWe reserve the right to close without a response\r\nenhancement requests which are incomplete.\r\n-->\r\n# Checklist\r\n<!--\r\nTo check an item on the list replace [ ] with [x].\r\n-->\r\n\r\n- [ x ] I have checked the [issues list](https://github.com/celery/celery/issues?q=is%3Aissue+label%3A%22Issue+Type%3A+Enhancement%22+-label%3A%22Category%3A+Documentation%22)\r\n  for similar or identical enhancement to an existing feature.\r\n- [ x ] I have checked the [pull requests list](https://github.com/celery/celery/pulls?q=is%3Apr+label%3A%22Issue+Type%3A+Enhancement%22+-label%3A%22Category%3A+Documentation%22)\r\n  for existing proposed enhancements.\r\n- [ x ] I have checked the [commit log](https://github.com/celery/celery/commits/main)\r\n  to find out if the if the same enhancement was already implemented in the\r\n  main branch.\r\n- [ x ] I have included all related issues and possible duplicate issues in this issue\r\n      (If there are none, check this box anyway).\r\n\r\n## Related Issues and Possible Duplicates\r\n<!--\r\nPlease make sure to search and mention any related issues\r\nor possible duplicates to this issue as requested by the checklist above.\r\n\r\nThis may or may not include issues in other repositories that the Celery project\r\nmaintains or other repositories that are dependencies of Celery.\r\n\r\nIf you don't know how to mention issues, please refer to Github's documentation\r\non the subject: https://help.github.com/en/articles/autolinked-references-and-urls#issues-and-pull-requests\r\n-->\r\n\r\n#### Related Issues\r\n\r\nhttps://github.com/sontek/pyramid_celery/issues/101\r\n\r\n#### Possible Duplicates\r\n\r\n- None\r\n\r\n# Brief Summary\r\n<!--\r\nPlease include a brief summary of what the enhancement is\r\nand why it is needed.\r\n-->\r\n\r\nThe  [pyramid-celery](https://github.com/sontek/pyramid_celery) package adds `ini` and `ini-var` options to the standard commands. These allow the standard Pyramid `ini` configuration files to config Celery. With current Celery however, only the `worker`, `beat`, and `events` are able to be hooked into pyramid-celery's approach because those commands are set with.\r\n\r\n```\r\ncontext_settings={\r\n    'allow_extra_args': True\r\n}\r\n```\r\nSee `beat` for example: https://github.com/celery/celery/blob/f3a2cf45a69b443cac6c79a5c85583c8bd91b0a3/celery/bin/beat.py#L11\r\n\r\nThe `shell` and `purge` commands for some reason do not have context_settings and so do not set `allow_extra_args`. See for example in `shell`, https://github.com/celery/celery/blob/f3a2cf45a69b443cac6c79a5c85583c8bd91b0a3/celery/bin/shell.py#LL82C1-L117C24\r\n\r\nThe consequence is that the `ini` command options cause errors since these are extra and unknown args to these commands. Excluding the `ini` config casues  `shell` when it comes up to not get the task registration configs and `purge` isn't able to see queues.\r\n\r\n# Design\r\n\r\n## Architectural Considerations\r\n<!--\r\nIf more components other than Celery are involved,\r\ndescribe them here and the effect it would have on Celery.\r\n-->\r\n[pyramid-celery](https://github.com/sontek/pyramid_celery) is on [pypi](https://pypi.org/project/pyramid-celery). Allows you to use pyramid .ini files to configure celery and have your pyramid configuration inside celery tasks.\r\n\r\n## Proposed Behavior\r\n<!--\r\nPlease describe in detail how this enhancement is going to change the behavior\r\nof an existing feature.\r\nDescribe what happens in case of failures as well if applicable.\r\n-->\r\nThis should not affect Celery functionality, but will allow pyramid-celery to function as expected. See related issue tracked in pyramid-celery here https://github.com/sontek/pyramid_celery/issues/101\r\n\r\n## Proposed UI/UX\r\n<!--\r\nPlease provide your ideas for the API, CLI options,\r\nconfiguration key names etc. that will be adjusted for this enhancement.\r\n-->\r\n\r\nCelery should add `context_settings` with `allow_extra_args`,\r\n```\r\ncontext_settings={\r\n    'allow_extra_args': True\r\n}\r\n```\r\nto both the `shell` and `purge` commands. This will allow projects like pyramid-celery to hook in their own custom configuration options using the recommended (by Celery) `celery_app.user_options['preload'].add()` and/or `celery_app.user_options[option].add()` approaches. See [here](https://github.com/celery/celery/blob/e7b47a62d789557cf18ed0e56e2dfb99a51a62f7/docs/userguide/extending.rst#adding-new-command-line-options). This will also make `shell` and `purge` commands consistent with other commands like `worker`, `beat`, and `events` that already have these settings.\r\n\r\n## Diagrams\r\n<!--\r\nPlease include any diagrams that might be relevant\r\nto the implementation of this enhancement such as:\r\n* Class Diagrams\r\n* Sequence Diagrams\r\n* Activity Diagrams\r\nYou can drag and drop images into the text box to attach them to this issue.\r\n-->\r\nN/A\r\n\r\n## Alternatives\r\n<!--\r\nIf you have considered any alternative implementations\r\ndescribe them in detail below.\r\n-->\r\nNone\r\n\n",
        "hints_text": "Hey @dpdoughe :wave:,\nThank you for opening an issue. We will get back to you as soon as we can.\nAlso, check out our [Open Collective](https://opencollective.com/celery) and consider backing us - every little helps!\n\nWe also offer priority support for our sponsors.\nIf you require immediate assistance please consider sponsoring us.\n\nThe inability to configure and run `purge` or `shell` commands with pyramid_celery persists with Celery v5.3.1\nI am open to contributions in this regard. my expectation is adding adding missing tests for the newly proposed/missing features",
        "created_at": "2023-07-14T06:23:15Z",
        "version": "5.3",
        "PASS_TO_PASS": [],
        "FAIL_TO_PASS": []
    },
    {
        "repo": "celery/celery",
        "pull_number": 8098,
        "instance_id": "celery__celery-8098",
        "issue_numbers": [
            "8080"
        ],
        "base_commit": "3bff3f06740a0d509f807e14702f7144b043ae54",
        "patch": "diff --git a/celery/result.py b/celery/result.py\nindex eb3e154933b..f66bade1d40 100644\n--- a/celery/result.py\n+++ b/celery/result.py\n@@ -14,7 +14,6 @@\n from .app import app_or_default\n from .exceptions import ImproperlyConfigured, IncompleteStream, TimeoutError\n from .utils.graph import DependencyGraph, GraphFormatter\n-from .utils.iso8601 import parse_iso8601\n \n try:\n     import tblib\n@@ -530,7 +529,7 @@ def date_done(self):\n         \"\"\"UTC date and time.\"\"\"\n         date_done = self._get_task_meta().get('date_done')\n         if date_done and not isinstance(date_done, datetime.datetime):\n-            return parse_iso8601(date_done)\n+            return datetime.datetime.fromisoformat(date_done)\n         return date_done\n \n     @property\ndiff --git a/celery/utils/iso8601.py b/celery/utils/iso8601.py\nindex 4f9d183312b..2a5ae69619f 100644\n--- a/celery/utils/iso8601.py\n+++ b/celery/utils/iso8601.py\n@@ -37,6 +37,8 @@\n \n from pytz import FixedOffset\n \n+from celery.utils.deprecated import warn\n+\n __all__ = ('parse_iso8601',)\n \n # Adapted from http://delete.me.uk/2005/03/iso8601.html\n@@ -53,6 +55,7 @@\n \n def parse_iso8601(datestring):\n     \"\"\"Parse and convert ISO-8601 string to datetime.\"\"\"\n+    warn(\"parse_iso8601\", \"v5.3\", \"v6\", \"datetime.datetime.fromisoformat\")\n     m = ISO8601_REGEX.match(datestring)\n     if not m:\n         raise ValueError('unable to parse date string %r' % datestring)\ndiff --git a/celery/utils/time.py b/celery/utils/time.py\nindex ed4008c6e48..984da17c80f 100644\n--- a/celery/utils/time.py\n+++ b/celery/utils/time.py\n@@ -13,7 +13,6 @@\n from pytz import utc\n \n from .functional import dictfilter\n-from .iso8601 import parse_iso8601\n from .text import pluralize\n \n __all__ = (\n@@ -257,7 +256,7 @@ def maybe_iso8601(dt):\n         return\n     if isinstance(dt, datetime):\n         return dt\n-    return parse_iso8601(dt)\n+    return datetime.fromisoformat(dt)\n \n \n def is_naive(dt):\n",
        "test_patch": "diff --git a/t/unit/tasks/test_tasks.py b/t/unit/tasks/test_tasks.py\nindex a636eac73be..0095bac3405 100644\n--- a/t/unit/tasks/test_tasks.py\n+++ b/t/unit/tasks/test_tasks.py\n@@ -13,7 +13,6 @@\n from celery.contrib.testing.mocks import ContextMock\n from celery.exceptions import Ignore, ImproperlyConfigured, Retry\n from celery.result import AsyncResult, EagerResult\n-from celery.utils.time import parse_iso8601\n \n try:\n     from urllib.error import HTTPError\n@@ -889,11 +888,11 @@ def assert_next_task_data_equal(self, consumer, presult, task_name,\n         assert task_headers['task'] == task_name\n         if test_eta:\n             assert isinstance(task_headers.get('eta'), str)\n-            to_datetime = parse_iso8601(task_headers.get('eta'))\n+            to_datetime = datetime.fromisoformat(task_headers.get('eta'))\n             assert isinstance(to_datetime, datetime)\n         if test_expires:\n             assert isinstance(task_headers.get('expires'), str)\n-            to_datetime = parse_iso8601(task_headers.get('expires'))\n+            to_datetime = datetime.fromisoformat(task_headers.get('expires'))\n             assert isinstance(to_datetime, datetime)\n         properties = properties or {}\n         for arg_name, arg_value in properties.items():\n",
        "problem_statement": "Deprecate iso8601 module\n<!--\r\nPlease fill this template entirely and do not erase parts of it.\r\nWe reserve the right to close without a response\r\nenhancement requests which are incomplete.\r\n-->\r\n# Checklist\r\n<!--\r\nTo check an item on the list replace [ ] with [x].\r\n-->\r\n\r\n- [x] I have checked the [issues list](https://github.com/celery/celery/issues?q=is%3Aissue+label%3A%22Issue+Type%3A+Enhancement%22+-label%3A%22Category%3A+Documentation%22)\r\n  for similar or identical enhancement to an existing feature.\r\n- [x] I have checked the [pull requests list](https://github.com/celery/celery/pulls?q=is%3Apr+label%3A%22Issue+Type%3A+Enhancement%22+-label%3A%22Category%3A+Documentation%22)\r\n  for existing proposed enhancements.\r\n- [x] I have checked the [commit log](https://github.com/celery/celery/commits/main)\r\n  to find out if the if the same enhancement was already implemented in the\r\n  main branch.\r\n- [x] I have included all related issues and possible duplicate issues in this issue\r\n      (If there are none, check this box anyway).\r\n\r\n## Related Issues and Possible Duplicates\r\n<!--\r\nPlease make sure to search and mention any related issues\r\nor possible duplicates to this issue as requested by the checklist above.\r\n\r\nThis may or may not include issues in other repositories that the Celery project\r\nmaintains or other repositories that are dependencies of Celery.\r\n\r\nIf you don't know how to mention issues, please refer to Github's documentation\r\non the subject: https://help.github.com/en/articles/autolinked-references-and-urls#issues-and-pull-requests\r\n-->\r\n\r\n#### Related Issues\r\n\r\n- None\r\n\r\n#### Possible Duplicates\r\n\r\n- None\r\n\r\n# Brief Summary\r\n<!--\r\nPlease include a brief summary of what the enhancement is\r\nand why it is needed.\r\n-->\r\n\r\n`celery.utils.iso8601` is historic module which `.parse_iso8601()` can be replaced by `datetime.datetime.fromisoformat()` as Python 3.7 or above is now supported.\r\n\r\nSuggest deprecate this module and use `datetime.datetime.fromisoformat()` internally.\r\n\r\n# Design\r\n\r\n## Architectural Considerations\r\n<!--\r\nIf more components other than Celery are involved,\r\ndescribe them here and the effect it would have on Celery.\r\n-->\r\nNone\r\n\r\n## Proposed Behavior\r\n<!--\r\nPlease describe in detail how this enhancement is going to change the behavior\r\nof an existing feature.\r\nDescribe what happens in case of failures as well if applicable.\r\n-->\r\n\r\n- `iso8601` module is still usable before v6.0.0, but with addition of deprecation warning\r\n- remove `iso8601` module in v6.0.0\r\n- replace all usage of `parse_iso8601()` in the library by `datetime.datetime.fromisoformat`, with compatibility of Python 3.7 to 3.11\r\n\r\n## Proposed UI/UX\r\n<!--\r\nPlease provide your ideas for the API, CLI options,\r\nconfiguration key names etc. that will be adjusted for this enhancement.\r\n-->\r\n\r\nN/A\r\n\r\n## Diagrams\r\n<!--\r\nPlease include any diagrams that might be relevant\r\nto the implementation of this enhancement such as:\r\n* Class Diagrams\r\n* Sequence Diagrams\r\n* Activity Diagrams\r\nYou can drag and drop images into the text box to attach them to this issue.\r\n-->\r\nN/A\r\n\r\n## Alternatives\r\n<!--\r\nIf you have considered any alternative implementations\r\ndescribe them in detail below.\r\n-->\r\nNone\r\n\n",
        "hints_text": "Hey @wongcht :wave:,\nThank you for opening an issue. We will get back to you as soon as we can.\nAlso, check out our [Open Collective](https://opencollective.com/celery) and consider backing us - every little helps!\n\nWe also offer priority support for our sponsors.\nIf you require immediate assistance please consider sponsoring us.\n\nif that is the case lets do it.",
        "created_at": "2023-03-02T17:16:26Z",
        "version": "5.3",
        "PASS_TO_PASS": [],
        "FAIL_TO_PASS": [
            "t/unit/tasks/test_tasks.py"
        ]
    },
    {
        "repo": "celery/celery",
        "pull_number": 7945,
        "instance_id": "celery__celery-7945",
        "issue_numbers": [
            "4806"
        ],
        "base_commit": "dd811b37717635b5f7151a7adf9f5bf12e1bc0c6",
        "patch": "diff --git a/CONTRIBUTORS.txt b/CONTRIBUTORS.txt\nindex fe420b14d67..e8c1dec868b 100644\n--- a/CONTRIBUTORS.txt\n+++ b/CONTRIBUTORS.txt\n@@ -291,3 +291,4 @@ Tizian Seehaus, 2022/02/09\n Oleh Romanovskyi, 2022/06/09\n JoonHwan Kim, 2022/08/01\n Kaustav Banerjee, 2022/11/10\n+Austin Snoeyink 2022/12/06\ndiff --git a/celery/app/defaults.py b/celery/app/defaults.py\nindex ce8d0ae1a90..65731e614c0 100644\n--- a/celery/app/defaults.py\n+++ b/celery/app/defaults.py\n@@ -78,6 +78,7 @@ def __repr__(self):\n         scheduler=Option('celery.beat:PersistentScheduler'),\n         schedule_filename=Option('celerybeat-schedule'),\n         sync_every=Option(0, type='int'),\n+        cron_starting_deadline=Option(None, type=int)\n     ),\n     broker=Namespace(\n         url=Option(None, type='string'),\ndiff --git a/celery/schedules.py b/celery/schedules.py\nindex 62940132098..9798579754f 100644\n--- a/celery/schedules.py\n+++ b/celery/schedules.py\n@@ -36,7 +36,6 @@\n {0._orig_day_of_week} (m/h/dM/MY/d)>\\\n \"\"\"\n \n-\n SOLAR_INVALID_LATITUDE = \"\"\"\\\n Argument latitude {lat} is invalid, must be between -90 and 90.\\\n \"\"\"\n@@ -608,16 +607,48 @@ def remaining_estimate(self, last_run_at, ffwd=ffwd):\n     def is_due(self, last_run_at):\n         \"\"\"Return tuple of ``(is_due, next_time_to_run)``.\n \n+        If :setting:`beat_cron_starting_deadline`  has been specified, the\n+        scheduler will make sure that the `last_run_at` time is within the\n+        deadline. This prevents tasks that could have been run according to\n+        the crontab, but didn't, from running again unexpectedly.\n+\n         Note:\n             Next time to run is in seconds.\n \n         SeeAlso:\n             :meth:`celery.schedules.schedule.is_due` for more information.\n         \"\"\"\n+\n         rem_delta = self.remaining_estimate(last_run_at)\n-        rem = max(rem_delta.total_seconds(), 0)\n+        rem_secs = rem_delta.total_seconds()\n+        rem = max(rem_secs, 0)\n         due = rem == 0\n-        if due:\n+\n+        deadline_secs = self.app.conf.beat_cron_starting_deadline\n+        has_passed_deadline = False\n+        if deadline_secs is not None:\n+            # Make sure we're looking at the latest possible feasible run\n+            # date when checking the deadline.\n+            last_date_checked = last_run_at\n+            last_feasible_rem_secs = rem_secs\n+            while rem_secs < 0:\n+                last_date_checked = last_date_checked + abs(rem_delta)\n+                rem_delta = self.remaining_estimate(last_date_checked)\n+                rem_secs = rem_delta.total_seconds()\n+                if rem_secs < 0:\n+                    last_feasible_rem_secs = rem_secs\n+\n+            # if rem_secs becomes 0 or positive, second-to-last\n+            # last_date_checked must be the last feasible run date.\n+            # Check if the last feasible date is within the deadline\n+            # for running\n+            has_passed_deadline = -last_feasible_rem_secs > deadline_secs\n+            if has_passed_deadline:\n+                # Should not be due if we've passed the deadline for looking\n+                # at past runs\n+                due = False\n+\n+        if due or has_passed_deadline:\n             rem_delta = self.remaining_estimate(self.now())\n             rem = max(rem_delta.total_seconds(), 0)\n         return schedstate(due, rem)\ndiff --git a/docs/userguide/configuration.rst b/docs/userguide/configuration.rst\nindex 5350d9fa2af..28b5a810ded 100644\n--- a/docs/userguide/configuration.rst\n+++ b/docs/userguide/configuration.rst\n@@ -3495,3 +3495,16 @@ changes to the schedule into account.\n Also when running Celery beat embedded (:option:`-B <celery worker -B>`)\n on Jython as a thread the max interval is overridden and set to 1 so\n that it's possible to shut down in a timely manner.\n+\n+.. setting:: beat_cron_starting_deadline\n+\n+``beat_cron_starting_deadline``\n+~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n+\n+.. versionadded:: 5.3\n+\n+Default: None.\n+\n+When using cron, the number of seconds :mod:`~celery.bin.beat` can look back\n+when deciding whether a cron schedule is due. When set to `None`, cronjobs that\n+are past due will always run immediately.\n",
        "test_patch": "diff --git a/t/unit/app/test_beat.py b/t/unit/app/test_beat.py\nindex 94fdb0b464f..84f36d04f86 100644\n--- a/t/unit/app/test_beat.py\n+++ b/t/unit/app/test_beat.py\n@@ -696,16 +696,19 @@ def now_func():\n                 'first_missed', 'first_missed',\n                 last_run_at=now_func() - timedelta(minutes=2),\n                 total_run_count=10,\n+                app=self.app,\n                 schedule=app_schedule['first_missed']['schedule']),\n             'second_missed': beat.ScheduleEntry(\n                 'second_missed', 'second_missed',\n                 last_run_at=now_func() - timedelta(minutes=2),\n                 total_run_count=10,\n+                app=self.app,\n                 schedule=app_schedule['second_missed']['schedule']),\n             'non_missed': beat.ScheduleEntry(\n                 'non_missed', 'non_missed',\n                 last_run_at=now_func() - timedelta(minutes=2),\n                 total_run_count=10,\n+                app=self.app,\n                 schedule=app_schedule['non_missed']['schedule']),\n         }\n \ndiff --git a/t/unit/app/test_schedules.py b/t/unit/app/test_schedules.py\nindex ec3baedce85..d6f555c2cf2 100644\n--- a/t/unit/app/test_schedules.py\n+++ b/t/unit/app/test_schedules.py\n@@ -800,3 +800,136 @@ def test_yearly_execution_is_not_due(self):\n             due, remaining = self.yearly.is_due(datetime(2009, 3, 12, 7, 30))\n             assert not due\n             assert remaining == 4 * 24 * 60 * 60 - 3 * 60 * 60\n+\n+    def test_execution_not_due_if_task_not_run_at_last_feasible_time_outside_deadline(\n+            self):\n+        \"\"\"If the crontab schedule was added after the task was due, don't\n+        immediately fire the task again\"\"\"\n+        # could have feasibly been run on 12/5 at 7:30, but wasn't.\n+        self.app.conf.beat_cron_starting_deadline = 3600\n+        last_run = datetime(2022, 12, 4, 10, 30)\n+        now = datetime(2022, 12, 5, 10, 30)\n+        expected_next_execution_time = datetime(2022, 12, 6, 7, 30)\n+        expected_remaining = (\n+                    expected_next_execution_time - now).total_seconds()\n+\n+        # Run the daily (7:30) crontab with the current date\n+        with patch_crontab_nowfun(self.daily, now):\n+            due, remaining = self.daily.is_due(last_run)\n+            assert remaining == expected_remaining\n+            assert not due\n+\n+    def test_execution_not_due_if_task_not_run_at_last_feasible_time_no_deadline_set(\n+            self):\n+        \"\"\"Same as above test except there's no deadline set, so it should be\n+         due\"\"\"\n+        last_run = datetime(2022, 12, 4, 10, 30)\n+        now = datetime(2022, 12, 5, 10, 30)\n+        expected_next_execution_time = datetime(2022, 12, 6, 7, 30)\n+        expected_remaining = (\n+                    expected_next_execution_time - now).total_seconds()\n+\n+        # Run the daily (7:30) crontab with the current date\n+        with patch_crontab_nowfun(self.daily, now):\n+            due, remaining = self.daily.is_due(last_run)\n+            assert remaining == expected_remaining\n+            assert due\n+\n+    def test_execution_due_if_task_not_run_at_last_feasible_time_within_deadline(\n+            self):\n+        # Could have feasibly been run on 12/5 at 7:30, but wasn't. We are\n+        # still within a 1 hour deadline from the\n+        # last feasible run, so the task should still be due.\n+        self.app.conf.beat_cron_starting_deadline = 3600\n+        last_run = datetime(2022, 12, 4, 10, 30)\n+        now = datetime(2022, 12, 5, 8, 0)\n+        expected_next_execution_time = datetime(2022, 12, 6, 7, 30)\n+        expected_remaining = (\n+                    expected_next_execution_time - now).total_seconds()\n+\n+        # run the daily (7:30) crontab with the current date\n+        with patch_crontab_nowfun(self.daily, now):\n+            due, remaining = self.daily.is_due(last_run)\n+            assert remaining == expected_remaining\n+            assert due\n+\n+    def test_execution_due_if_task_not_run_at_any_feasible_time_within_deadline(\n+            self):\n+        # Could have feasibly been run on 12/4 at 7:30, or 12/5 at 7:30,\n+        # but wasn't. We are still within a 1 hour\n+        # deadline from the last feasible run (12/5), so the task should\n+        # still be due.\n+        self.app.conf.beat_cron_starting_deadline = 3600\n+        last_run = datetime(2022, 12, 3, 10, 30)\n+        now = datetime(2022, 12, 5, 8, 0)\n+        expected_next_execution_time = datetime(2022, 12, 6, 7, 30)\n+        expected_remaining = (\n+                    expected_next_execution_time - now).total_seconds()\n+\n+        # Run the daily (7:30) crontab with the current date\n+        with patch_crontab_nowfun(self.daily, now):\n+            due, remaining = self.daily.is_due(last_run)\n+            assert remaining == expected_remaining\n+            assert due\n+\n+    def test_execution_not_due_if_task_not_run_at_any_feasible_time_outside_deadline(\n+            self):\n+        \"\"\"Verifies that remaining is still the time to the next\n+        feasible run date even though the original feasible date\n+        was passed over in favor of a newer one.\"\"\"\n+        # Could have feasibly been run on 12/4 or 12/5 at 7:30,\n+        # but wasn't.\n+        self.app.conf.beat_cron_starting_deadline = 3600\n+        last_run = datetime(2022, 12, 3, 10, 30)\n+        now = datetime(2022, 12, 5, 11, 0)\n+        expected_next_execution_time = datetime(2022, 12, 6, 7, 30)\n+        expected_remaining = (\n+                    expected_next_execution_time - now).total_seconds()\n+\n+        # run the daily (7:30) crontab with the current date\n+        with patch_crontab_nowfun(self.daily, now):\n+            due, remaining = self.daily.is_due(last_run)\n+            assert remaining == expected_remaining\n+            assert not due\n+\n+    def test_execution_not_due_if_last_run_in_future(self):\n+        # Should not run if the last_run hasn't happened yet.\n+        last_run = datetime(2022, 12, 6, 7, 30)\n+        now = datetime(2022, 12, 5, 10, 30)\n+        expected_next_execution_time = datetime(2022, 12, 7, 7, 30)\n+        expected_remaining = (\n+                    expected_next_execution_time - now).total_seconds()\n+\n+        # Run the daily (7:30) crontab with the current date\n+        with patch_crontab_nowfun(self.daily, now):\n+            due, remaining = self.daily.is_due(last_run)\n+            assert not due\n+            assert remaining == expected_remaining\n+\n+    def test_execution_not_due_if_last_run_at_last_feasible_time(self):\n+        # Last feasible time is 12/5 at 7:30\n+        last_run = datetime(2022, 12, 5, 7, 30)\n+        now = datetime(2022, 12, 5, 10, 30)\n+        expected_next_execution_time = datetime(2022, 12, 6, 7, 30)\n+        expected_remaining = (\n+                    expected_next_execution_time - now).total_seconds()\n+\n+        # Run the daily (7:30) crontab with the current date\n+        with patch_crontab_nowfun(self.daily, now):\n+            due, remaining = self.daily.is_due(last_run)\n+            assert remaining == expected_remaining\n+            assert not due\n+\n+    def test_execution_not_due_if_last_run_past_last_feasible_time(self):\n+        # Last feasible time is 12/5 at 7:30\n+        last_run = datetime(2022, 12, 5, 8, 30)\n+        now = datetime(2022, 12, 5, 10, 30)\n+        expected_next_execution_time = datetime(2022, 12, 6, 7, 30)\n+        expected_remaining = (\n+                    expected_next_execution_time - now).total_seconds()\n+\n+        # Run the daily (7:30) crontab with the current date\n+        with patch_crontab_nowfun(self.daily, now):\n+            due, remaining = self.daily.is_due(last_run)\n+            assert remaining == expected_remaining\n+            assert not due\n",
        "problem_statement": "celery.schedules.crontab is_due logic can trigger periodic celery beat tasks at arbitrary times unrelated to the crontab parameters when last_run_at value is sufficiently old\nThere's an issue in the implementation of `celery.schedules.crontab` method that can cause `crontab.is_due` to claim a schedule is due at a time that is completely unrelated to the given crontab parameters. This appears to happen in cases where the `last_run_at` value is older than the most recent feasible time the schedule could have run. It looks like that this issue was introduced as part of complex logic added nearly 8 years ago to improve the accuracy of time remaining estimates for `crontab` periodic tasks: 4ed89ec49582b540149cf06047f091ebd20fb300\n\n## Checklist\nIssue first observed in a celery deployment running celery v3.1.19\n\nFrom inspecting the `celery.schedules.crontab` code it appears likely that this issue is present in all celery versions as far back as v2.1.0 through to v4.1.1 .\n\nUnit tests (please see below) confirm issue is still present in master (b599b96960be9dd42b3dee82a58bd1d711df0317 at time of writing).\n\n## Steps to reproduce\nPlease apply this patch to celery master branch, remove `@skip.todo` from the first new test, run unit tests, observe the first of these added unit tests fails:\n\n```\ndiff --git a/t/unit/app/test_schedules.py b/t/unit/app/test_schedules.py\nindex a7b3025..0340461 100644\n--- a/t/unit/app/test_schedules.py\n+++ b/t/unit/app/test_schedules.py\n@@ -26,6 +26,18 @@ def patch_crontab_nowfun(cls, retval):\n         cls.nowfun = prev_nowfun\n \n \n+def is_time_feasible_wrt_crontab_schedule(t, z):\n+    # z : celery.schedules.crontab instance\n+    t = z.maybe_make_aware(t)\n+    return (\n+        t.month in z.month_of_year and\n+        (t.isoweekday() % 7) in z.day_of_week and\n+        t.day in z.day_of_month and\n+        t.hour in z.hour and\n+        t.minute in z.minute\n+    )\n+\n+\n @skip.unless_module('ephem')\n class test_solar:\n \n@@ -803,3 +815,59 @@ class test_crontab_is_due:\n             due, remaining = self.yearly.is_due(datetime(2009, 3, 12, 7, 30))\n             assert not due\n             assert remaining == 4 * 24 * 60 * 60 - 3 * 60 * 60\n+\n+    @skip.todo('FIXME crontab logic is defective when last_run_at is older than the most recent feasible time wrt schedule')\n+    def test_daily_execution_if_last_run_at_was_days_ago_and_current_time_does_not_match_crontab_schedule_then_execution_is_not_due(self):\n+        z = self.crontab(hour=7, minute=30)\n+        last_run_at = datetime(2018, 6, 1, 7, 30)\n+        now = datetime(2018, 6, 9, 23, 48)\n+        expected_next_execution_time = datetime(2018, 6, 10, 7, 30)\n+        expected_remaining = (expected_next_execution_time - now).total_seconds()\n+        # check our assumptions\n+        assert is_time_feasible_wrt_crontab_schedule(last_run_at, z)\n+        assert not is_time_feasible_wrt_crontab_schedule(now, z)\n+        assert is_time_feasible_wrt_crontab_schedule(expected_next_execution_time, z)\n+        assert now < expected_next_execution_time\n+        assert expected_remaining == (7 * 60 + 30 + 12) * 60\n+        # test is_due\n+        with patch_crontab_nowfun(z, now):\n+            due, remaining = z.is_due(last_run_at=last_run_at)\n+            assert remaining == expected_remaining\n+            assert not due\n+\n+    def test_daily_execution_if_last_run_at_was_the_most_recent_feasible_time_wrt_schedule_in_past_and_current_time_does_not_match_crontab_schedule_then_execution_is_not_due(self):\n+        z = self.crontab(hour=7, minute=30)\n+        last_run_at = datetime(2018, 6, 9, 7, 30)\n+        now = datetime(2018, 6, 9, 23, 48)\n+        expected_next_execution_time = datetime(2018, 6, 10, 7, 30)\n+        expected_remaining = (expected_next_execution_time - now).total_seconds()\n+        # check our assumptions\n+        assert is_time_feasible_wrt_crontab_schedule(last_run_at, z)\n+        assert not is_time_feasible_wrt_crontab_schedule(now, z)\n+        assert is_time_feasible_wrt_crontab_schedule(expected_next_execution_time, z)\n+        assert now < expected_next_execution_time\n+        assert expected_remaining == (7 * 60 + 30 + 12) * 60\n+        # test is_due\n+        with patch_crontab_nowfun(z, now):\n+            due, remaining = z.is_due(last_run_at=last_run_at)\n+            assert remaining == expected_remaining\n+            assert not due\n+\n+    def test_daily_execution_if_last_run_at_was_more_recent_than_the_most_recent_feasible_time_wrt_schedule_in_past_and_current_time_does_not_match_crontab_schedule_then_execution_is_not_due(self):\n+        z = self.crontab(hour=7, minute=30)\n+        last_run_at = datetime(2018, 6, 9, 10, 30) # not feasible wrt to current schedule. case can happen if schedule is modified after a run\n+        now = datetime(2018, 6, 9, 23, 48)\n+        expected_next_execution_time = datetime(2018, 6, 10, 7, 30)\n+        expected_remaining = (expected_next_execution_time - now).total_seconds()\n+        # check our assumptions\n+        assert not is_time_feasible_wrt_crontab_schedule(last_run_at, z)\n+        assert not is_time_feasible_wrt_crontab_schedule(now, z)\n+        assert is_time_feasible_wrt_crontab_schedule(expected_next_execution_time, z)\n+        assert now < expected_next_execution_time\n+        assert expected_remaining == (7 * 60 + 30 + 12) * 60\n+        # test is_due\n+        with patch_crontab_nowfun(z, now):\n+            due, remaining = z.is_due(last_run_at=last_run_at)\n+            assert remaining == expected_remaining\n+            assert not due\n+\n```\n\n## Expected behavior\nNo matter what the value of `last_run_at` is, `crontab.is_due(last_run_at)` should never return `schedstate(True, rem)` when the current time `now` is not feasible with respect to the given crontab parameters.\n\n## Actual behavior\nif `last_run_at` value is older than the most recent time that is feasible with respect to the given crontab parameters then `crontab.is_due(last_run_at)` returns `schedstate(True, rem)`  when the current time is not feasible with respect to the crontab parameters.\n\n## Comments\nThis behaviour is surprising as it is an undocumented departure from cron-like behaviour. This behaviour is somewhat like an undocumented variant of uncontrollable `anacron` behaviour. \"Uncontrollable\" in the sense that unlike `anacrontab`'s `START_HOURS_RANGE` parameter - there is no control at all over when tasks will be run when a scheduled execution is missed.\n\nWe experience this issue in production using the venerable Celery version of 3.1.19 : we have a celery beat process that is backed by a database using custom scheduler code that is derived from the django-celery-beat scheduler. Suppose we stop this celery beat process for some reason such as scheduled maintenance or during a deployment that needs to redeploy code to our celery cluster. When we later restart celery beat again then some or all `celery.schedules.crontab` scheduled tasks may immediately execute if there was a time during the celery beat downtime period that matches the crontab parameters.\n\nOne hack that can mitigate this behaviour is updating the \"last_run_at\" value for all celery crontab scheduled periodic tasks to the current time when celery beat starts, before celery beat makes any calls to the `celery.schedules.crontab.is_due` method.\n\n\n",
        "hints_text": "I am in the process of rewriting the `celery.schedules.crontab` logic to fix this cleanly, if i can get the green light from my client to release a fix upstream i will submit a pull request with a proposed patch to fix this within the next week or two.\r\n\r\n\n@fcostin did you ever complete your `crontab` rewrite and/or (not) get permission to release?\nCan you send a PR with proposed fix?\n@fdemmer -\r\n\r\nOne crude way to fix this is to simply revert the old change that introduced this issue: https://github.com/celery/celery/commit/4ed89ec49582b540149cf06047f091ebd20fb300 , in particular the parts of the patch to `celery/schedules.py` that introduce the much more complicated logic that estimates the time remaining until the next job.\r\n\r\nThis would have downside of breaking the logic that estimates when the next scheduled task is due, and causing the scheduler to need to poll every second to re-check if a task is due yet. But it would fix this issue.\r\n\r\nI wrote a better patch for fixing this last year (that didn't rely on polling every 1 second, and could estimate remaining time until the next scheduled task) which resolved the issue internally but finished up my contract shortly after and ran out of time to lobby for permission to release the fix upstream. I'll reach out and see if anyone there is willing to work with me to get the patch released (chances of this are low, but worth a try...).\r\n\nthanks for the response @fcostin :)\r\n\r\nmy requirement is adding tz support. i thought about rewriting/fixing/adding to celery's crontab, but decided it would be better to not hack around in that code or pile up on top, so i wrote my own using [tzcron](https://github.com/bloomberg/tzcron) to parse the cron expression and calculate the next event.\r\n\r\n- it calculates the timestamp for the next trigger based only on \"now\" (ignoring `last_run_at`), so the bug from this issue _should_ be fixed.\r\n- the cron parameters can be passed as string or separate args, in the order requested in #4570\r\n\r\nhttps://gist.github.com/fdemmer/7551bff2bab80b56aac5018060aded55\r\n\r\nit hasn't been used a lot and has no tests, but _seems_ to work and is licensed under MIT like all my gists.\nhi @fdemmer -- adding timezone support sounds like a great idea, as does your implementation that avoids using the existing celery crontab scheduler logic completely.\r\n\r\nYour `pytzcrontab` implementation looks pretty good . If i was aware of this last year that would have likely been a cleaner fix than my patch. thanks for sharing!\r\n\r\n> it hasn't been used a lot and has no tests, but seems to work and is licensed under MIT like all my gists.\r\n\r\nSounds promising!\r\n\r\nI have subjected your `pytzcrontab` class to the existing unit tests for the crontab scheduler -- with some patches to those unit tests to fix up timezones as necessary -- including adding three new tests from my patch in this issue.\r\n\r\nhere are my experimental patches, including adding `celery-tzcron.py` from your gist as `celery/scheduler_tzcron.py`:\r\n\r\nhttps://github.com/fcostin/celery/commits/scheduler_tzcron_experiments\r\n\r\nthe results are fairly good:\r\n\r\n1. `pytzcrontab` appears to fix this issue, as you predict. this makes sense.\r\n2. with a small patch for compatibility with the existing `crontab` scheduler to define `hour` ... `day_of_year` properties, `pytzcrontab` passes most of the old unit tests\r\n3. with some more patches to your `is_due` and `remaining_estimate` logic, the `pytzcrontab` implementation behaves in a closer way to how the existing `crontab` class decides when things are due. This change appears to be necessary so that `pytzcrontab` does not say the schedule is due when the schedule last ran a very short time ago (e.g. 0 seconds ago!). i am not completely happy with my proposed change here, it doesn't seem completely clean, maybe you can think of a nicer way to do it.\r\n3. `pytzcrontab` introduces one regression that the existing celery unit tests can detect-- it goes into an infinite loop if we try to schedule something on an impossible day (31st of april) . I looked for an obvious way to avoid this but didn't find a good one so i've marked the test as skipped, but this would be good to fix. I guess it could be fixed by additional up-front validation logic, but there is still some risk that a gap between validation and the behaviour of the `tzcron` library might lead to an infinite loop.\r\n\r\n```\r\n   @pytest.mark.skip(\"broken - pytzcrontab goes into an infinite loop here\")\r\n    def test_invalid_specification(self):\r\n        # *** WARNING ***\r\n        # This test triggers an infinite loop in case of a regression\r\n        with pytest.raises(RuntimeError):\r\n            self.next_ocurrance(\r\n                self.pytzcrontab(day_of_month=31, month_of_year=4),\r\n                datetime_utc(2010, 1, 28, 14, 30, 15),\r\n            )\r\n```\r\n\r\nWhat do you think?\r\n\r\nWould it make sense to contribute something like this as a pull request into celery itself?\nThis issue is fairly old is there a fix or a work around for this? I see the gist above but I'd rather not have to maintain some other version of celery.\r\n\r\nRight now I'm facing an issue with duplicate ETL imports because of this. I run all crontab schedules but if I make an on the fly change, either adding a new periodic task or changing the schedule of one, it will trigger ALL of my tasks to run.\nIn all honesty this seems like its been an issue for a very long time and frankly surprised its not a much higher priority bug to be fixed. For a scheduling app to incorrectly schedule a task seems like a pretty big issue.\r\n\r\nAnyways, I appreciate you taking the time to respond. I can try to look at the code, but in all honesty I'm not very good with following large projects like Celery. If I get some time over Christmas holiday I will have a go at trying to see where it can be fixed.\r\n\r\nStay safe and have a wonderful holiday!\n> In all honesty this seems like its been an issue for a very long time and frankly surprised its not a much higher priority bug to be fixed. For a scheduling app to incorrectly schedule a task seems like a pretty big issue.\r\n> \r\n> Anyways, I appreciate you taking the time to respond. I can try to look at the code, but in all honesty I'm not very good with following large projects like Celery. If I get some time over Christmas holiday I will have a go at trying to see where it can be fixed.\r\n> \r\n> Stay safe and have a wonderful holiday!\r\n\r\nif you can take the lead we could help you guide you through all the way\nSo now I'm not sure if my issue is related to this. I was trying to reproduce this with my app and wasn't able to reproduce it until today.\r\n\r\nThe way it triggered wasn't by adding/removing/updating a periodic task, but by adding a new schedule and then assigning that to a newly created periodic task. I don't know if this is due to the library I'm using to store it in a database or relating to this issue. I'll have to dig a bit deeper when I can.\nWe ran into this issue on our production setup and charged our subscription customers ahead of schedule when we restarted the services with a slight change in the scheduled time. This should be a higher priority bug.\r\n\r\nI will try and post the steps to reproduce this reliably.\nAs a work around: since I'm using an external scheduler library for managing the beat schedules I just simply have an event listener on beat startup null out the last_run_at field for each schedule in the database. This will prevent beat from running any of the schedules prematurely.\nI am not sure if we are experiencing this same issue, here is what the celerybeat-schedule looks like:\r\n\r\n```\r\n>>> schedule = shelve.open(\"celerybeat-schedule\", writeback=True)\r\n>>> task = schedule[\"entries\"][\"My task\"]\r\n>>> task.last_run_at\r\ndatetime.datetime(2021, 5, 18, 8, 36, 0, 99, tzinfo=<UTC>)\r\n>>> task.is_due()\r\nschedstate(is_due=True, next=48.84625)\r\n>>> task.schedule\r\n<crontab: * 8 * * * (m/h/d/dM/MY)>\r\n>>> datetime.now()\r\ndatetime.datetime(2021, 5, 18, 8, 39, 36, 601785)\r\n```\r\nThe above task runs continously between 8am and 9 am __sometimes__ but not always... Using `celery==5.0.5`\n@thedrow I can't commit as I don't have enough time, not expecting a fix, was just unsure if this bug is the same described above. I have now changed my crontab from 8am to 7:59 and waiting to see if the problem resurfaces. \r\n\r\n**Update**\r\nWith time set to 7:59 the task only runs once at the specified time, haven't observed the issue over the last two weeks.\nI have the same issue. I use crontab(hour='*/3') and once the top of the hour hits, it runs on an infinite loop.",
        "created_at": "2022-12-06T15:35:26Z",
        "version": "5.3",
        "PASS_TO_PASS": [],
        "FAIL_TO_PASS": [
            "t/unit/app/test_beat.py",
            "t/unit/app/test_schedules.py"
        ]
    },
    {
        "repo": "celery/celery",
        "pull_number": 7734,
        "instance_id": "celery__celery-7734",
        "issue_numbers": [
            "6622"
        ],
        "base_commit": "fbae71ca2bc2eb68988131f5719a1dc5807d58fd",
        "patch": "diff --git a/celery/backends/dynamodb.py b/celery/backends/dynamodb.py\nindex 7c2f1ca5b39..fbc8bcf160e 100644\n--- a/celery/backends/dynamodb.py\n+++ b/celery/backends/dynamodb.py\n@@ -201,28 +201,25 @@ def _get_or_create_table(self):\n         \"\"\"Create table if not exists, otherwise return the description.\"\"\"\n         table_schema = self._get_table_schema()\n         try:\n-            table_description = self._client.create_table(**table_schema)\n-            logger.info(\n-                'DynamoDB Table {} did not exist, creating.'.format(\n-                    self.table_name\n-                )\n-            )\n-            # In case we created the table, wait until it becomes available.\n-            self._wait_for_table_status('ACTIVE')\n-            logger.info(\n-                'DynamoDB Table {} is now available.'.format(\n-                    self.table_name\n-                )\n-            )\n-            return table_description\n+            return self._client.describe_table(TableName=self.table_name)\n         except ClientError as e:\n             error_code = e.response['Error'].get('Code', 'Unknown')\n \n-            # If table exists, do not fail, just return the description.\n-            if error_code == 'ResourceInUseException':\n-                return self._client.describe_table(\n-                    TableName=self.table_name\n+            if error_code == 'ResourceNotFoundException':\n+                table_description = self._client.create_table(**table_schema)\n+                logger.info(\n+                    'DynamoDB Table {} did not exist, creating.'.format(\n+                        self.table_name\n+                    )\n+                )\n+                # In case we created the table, wait until it becomes available.\n+                self._wait_for_table_status('ACTIVE')\n+                logger.info(\n+                    'DynamoDB Table {} is now available.'.format(\n+                        self.table_name\n+                    )\n                 )\n+                return table_description\n             else:\n                 raise e\n \n",
        "test_patch": "diff --git a/t/unit/backends/test_dynamodb.py b/t/unit/backends/test_dynamodb.py\nindex 6fd2625c0cb..a27af96d6ff 100644\n--- a/t/unit/backends/test_dynamodb.py\n+++ b/t/unit/backends/test_dynamodb.py\n@@ -121,39 +121,34 @@ def test_get_client_time_to_live_called(\n         mock_set_table_ttl.assert_called_once()\n \n     def test_get_or_create_table_not_exists(self):\n+        from botocore.exceptions import ClientError\n+\n         self.backend._client = MagicMock()\n         mock_create_table = self.backend._client.create_table = MagicMock()\n+        client_error = ClientError(\n+            {\n+                'Error': {\n+                    'Code': 'ResourceNotFoundException'\n+                }\n+            },\n+            'DescribeTable'\n+        )\n         mock_describe_table = self.backend._client.describe_table = \\\n             MagicMock()\n-\n-        mock_describe_table.return_value = {\n-            'Table': {\n-                'TableStatus': 'ACTIVE'\n-            }\n-        }\n+        mock_describe_table.side_effect = client_error\n+        self.backend._wait_for_table_status = MagicMock()\n \n         self.backend._get_or_create_table()\n+        mock_describe_table.assert_called_once_with(\n+            TableName=self.backend.table_name\n+        )\n         mock_create_table.assert_called_once_with(\n             **self.backend._get_table_schema()\n         )\n \n     def test_get_or_create_table_already_exists(self):\n-        from botocore.exceptions import ClientError\n-\n         self.backend._client = MagicMock()\n         mock_create_table = self.backend._client.create_table = MagicMock()\n-        client_error = ClientError(\n-            {\n-                'Error': {\n-                    'Code': 'ResourceInUseException',\n-                    'Message': 'Table already exists: {}'.format(\n-                        self.backend.table_name\n-                    )\n-                }\n-            },\n-            'CreateTable'\n-        )\n-        mock_create_table.side_effect = client_error\n         mock_describe_table = self.backend._client.describe_table = \\\n             MagicMock()\n \n@@ -167,6 +162,7 @@ def test_get_or_create_table_already_exists(self):\n         mock_describe_table.assert_called_once_with(\n             TableName=self.backend.table_name\n         )\n+        mock_create_table.assert_not_called()\n \n     def test_wait_for_table_status(self):\n         self.backend._client = MagicMock()\n",
        "problem_statement": "dynamoDB result backend incorrect exception handling when table exists\nThe following code\n\nhttps://github.com/celery/celery/blob/d0f5300691ca594f2311daf542aa63367622c027/celery/backends/dynamodb.py#L192\n\ntries to create or get the table. In case the table exists and the role executing that code on AWS does not have the `CreateTable` permission, the raised exception is not the one expected by that particular line. Yet the table exists _and_ the exception is raised because the code tries to create it while lacking permissions.\n\nTo reproduce:\n\n\n* celery 5.0.5\n* create the result backend table and give the following permissions to the role executing celery on that table:\n\n```\n   \"dynamodb:DescribeTable\",\n   \"dynamodb:PutItem\",\n   \"dynamodb:UpdateItem\",\n   \"dynamodb:DeleteItem\",\n   \"dynamodb:BatchWriteItem\",\n   \"dynamodb:GetItem\",\n   \"dynamodb:BatchGetItem\",\n   \"dynamodb:Scan\",\n   \"dynamodb:Query\",\n   \"dynamodb:ConditionCheckItem\"\n```\n\n* remove the permission CreateTable from the role executing the code\n\nPossible solution:\n\n* handle the check of the table existence with another boto3 call such as [`describe_table`](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/dynamodb.html#DynamoDB.Client.describe_table) and then fall-back into the table creation\n* provide a configuration that, when indicated, assumes the existence of the table\n* handle that exception differently\n\n\n",
        "hints_text": "> Possible solution:\r\n> \r\n>     * handle the check of the table existence with another boto3 call such as [`describe_table`](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/dynamodb.html#DynamoDB.Client.describe_table) and then fall-back into the table creation\r\n> \r\n>     * provide a configuration that, when indicated, assumes the existence of the table\r\n> \r\n>     * handle that exception differently\r\n\r\nI am no expert on dynamo DB. But if you can come with a change request as your proposed possible solutions we could verify & help to improve.\n@lyajedi let's continue here",
        "created_at": "2022-08-30T15:23:38Z",
        "version": "5.3",
        "PASS_TO_PASS": [],
        "FAIL_TO_PASS": [
            "t/unit/backends/test_dynamodb.py"
        ]
    },
    {
        "repo": "celery/celery",
        "pull_number": 7609,
        "instance_id": "celery__celery-7609",
        "issue_numbers": [
            "3576"
        ],
        "base_commit": "ec3714edf37e773ca5372f71f7f4ee5b1b33dd5d",
        "patch": "diff --git a/celery/worker/state.py b/celery/worker/state.py\nindex 3afb2e8e3b9..97f49150286 100644\n--- a/celery/worker/state.py\n+++ b/celery/worker/state.py\n@@ -32,18 +32,18 @@\n }\n \n #: maximum number of revokes to keep in memory.\n-REVOKES_MAX = 50000\n+REVOKES_MAX = int(os.environ.get('CELERY_WORKER_REVOKES_MAX', 50000))\n \n #: maximum number of successful tasks to keep in memory.\n-SUCCESSFUL_MAX = 1000\n+SUCCESSFUL_MAX = int(os.environ.get('CELERY_WORKER_SUCCESSFUL_MAX', 1000))\n \n #: how many seconds a revoke will be active before\n #: being expired when the max limit has been exceeded.\n-REVOKE_EXPIRES = 10800\n+REVOKE_EXPIRES = float(os.environ.get('CELERY_WORKER_REVOKE_EXPIRES', 10800))\n \n #: how many seconds a successful task will be cached in memory\n #: before being expired when the max limit has been exceeded.\n-SUCCESSFUL_EXPIRES = 10800\n+SUCCESSFUL_EXPIRES = float(os.environ.get('CELERY_WORKER_SUCCESSFUL_EXPIRES', 10800))\n \n #: Mapping of reserved task_id->Request.\n requests = {}\ndiff --git a/docs/userguide/workers.rst b/docs/userguide/workers.rst\nindex 9b8c2a4387d..9f75bb9aeda 100644\n--- a/docs/userguide/workers.rst\n+++ b/docs/userguide/workers.rst\n@@ -358,6 +358,20 @@ Commands\n All worker nodes keeps a memory of revoked task ids, either in-memory or\n persistent on disk (see :ref:`worker-persistent-revokes`).\n \n+.. note::\n+\n+    The maximum number of revoked tasks to keep in memory can be\n+    specified using the ``CELERY_WORKER_REVOKES_MAX`` environment\n+    variable, which defaults to 50000. When the limit has been exceeded,\n+    the revokes will be active for 10800 seconds (3 hours) before being\n+    expired. This value can be changed using the\n+    ``CELERY_WORKER_REVOKE_EXPIRES`` environment variable.\n+\n+    Memory limits can also be set for successful tasks through the\n+    ``CELERY_WORKER_SUCCESSFUL_MAX`` and\n+    ``CELERY_WORKER_SUCCESSFUL_EXPIRES`` environment variables, and\n+    default to 1000 and 10800 respectively.\n+\n When a worker receives a revoke request it will skip executing\n the task, but it won't terminate an already executing task unless\n the `terminate` option is set.\n",
        "test_patch": "diff --git a/t/unit/worker/test_state.py b/t/unit/worker/test_state.py\nindex 571fc4be32d..7388c49bb9f 100644\n--- a/t/unit/worker/test_state.py\n+++ b/t/unit/worker/test_state.py\n@@ -1,4 +1,7 @@\n+import os\n import pickle\n+import sys\n+from importlib import import_module\n from time import time\n from unittest.mock import Mock, patch\n \n@@ -187,3 +190,32 @@ def test_ready(self, requests=[SimpleReq('foo'),\n         for request in requests:\n             state.task_ready(request)\n         assert len(state.active_requests) == 0\n+\n+\n+class test_state_configuration():\n+\n+    @staticmethod\n+    def import_state():\n+        with patch.dict(sys.modules):\n+            del sys.modules['celery.worker.state']\n+            return import_module('celery.worker.state')\n+\n+    @patch.dict(os.environ, {\n+        'CELERY_WORKER_REVOKES_MAX': '50001',\n+        'CELERY_WORKER_SUCCESSFUL_MAX': '1001',\n+        'CELERY_WORKER_REVOKE_EXPIRES': '10801',\n+        'CELERY_WORKER_SUCCESSFUL_EXPIRES': '10801',\n+    })\n+    def test_custom_configuration(self):\n+        state = self.import_state()\n+        assert state.REVOKES_MAX == 50001\n+        assert state.SUCCESSFUL_MAX == 1001\n+        assert state.REVOKE_EXPIRES == 10801\n+        assert state.SUCCESSFUL_EXPIRES == 10801\n+\n+    def test_default_configuration(self):\n+        state = self.import_state()\n+        assert state.REVOKES_MAX == 50000\n+        assert state.SUCCESSFUL_MAX == 1000\n+        assert state.REVOKE_EXPIRES == 10800\n+        assert state.SUCCESSFUL_EXPIRES == 10800\n",
        "problem_statement": "make REVOKES_MAX and REVOKE_EXPIRES configurable\nValues of REVOKE_EXPIRES and REVOKES_MAX in worker/state.py  are hardcoded.\n\nThis should be configurable. Some of us really needed to change this.\n\n\n",
        "hints_text": "any suggested changes on your mind? feel free send a PR\nwill try, thanks for pushing celery forward :)\r\n\r\n\nI think this can be programmatically supported via adding `control` commands, similar to the following:\r\n\r\n```python\r\nfrom celery.worker.control import control_command\r\n\r\nfrom celery.worker import state as worker_state\r\n\r\n@control_command(\r\n    args=[('n', int)],\r\n    signature='[N={}]'.format(worker_state.REVOKES_MAX),  # <- used for help on the command-line.\r\n)\r\ndef revokes_max(state, n=worker_state.REVOKES_MAX):\r\n    if n != worker_state.revoked.maxlen:\r\n        prev_max_len = worker_state.revoked.maxlen\r\n        worker_state.revoked.maxlen = n\r\n        if n < prev_max_len:\r\n            worker_state.revoked.purge()\r\n    return {'ok': 'updated revoked task max length.'}\r\n\r\n\r\n@control_command(\r\n    args=[('n', int)],\r\n    signature='[N={}]'.format(worker_state.REVOKE_EXPIRES),  # <- used for help on the command-line.\r\n)\r\ndef revokes_expires(state, n=worker_state.REVOKE_EXPIRES):\r\n    if n != worker_state.revoked.expires:\r\n        prev_expires = worker_state.revoked.expires\r\n        worker_state.revoked.expires = n\r\n        if n < prev_expires:\r\n            worker_state.revoked.purge()\r\n    return {'ok': 'updated revoked task expiration.'}\r\n```\r\n\r\nOf course, _not_ having to call control commands right after a deploy of workers comes up, and instead make it configurable like many other parameters in the conf, would be ideal. But, this is a stop-gap (and also allows it to be changed on the fly, which is at least minorly useful).",
        "created_at": "2022-07-05T02:46:40Z",
        "version": "5.3",
        "PASS_TO_PASS": [],
        "FAIL_TO_PASS": [
            "t/unit/worker/test_state.py"
        ]
    },
    {
        "repo": "celery/celery",
        "pull_number": 7608,
        "instance_id": "celery__celery-7608",
        "issue_numbers": [
            "5836"
        ],
        "base_commit": "ec3714edf37e773ca5372f71f7f4ee5b1b33dd5d",
        "patch": "diff --git a/celery/apps/beat.py b/celery/apps/beat.py\nindex 8652c62730a..dbed1ed442f 100644\n--- a/celery/apps/beat.py\n+++ b/celery/apps/beat.py\n@@ -44,7 +44,8 @@ def __init__(self, max_interval=None, app=None,\n                  scheduler=None,\n                  scheduler_cls=None,  # XXX use scheduler\n                  redirect_stdouts=None,\n-                 redirect_stdouts_level=None, **kwargs):\n+                 redirect_stdouts_level=None,\n+                 quiet=False, **kwargs):\n         self.app = app = app or self.app\n         either = self.app.either\n         self.loglevel = loglevel\n@@ -56,6 +57,7 @@ def __init__(self, max_interval=None, app=None,\n             'worker_redirect_stdouts', redirect_stdouts)\n         self.redirect_stdouts_level = either(\n             'worker_redirect_stdouts_level', redirect_stdouts_level)\n+        self.quiet = quiet\n \n         self.max_interval = max_interval\n         self.socket_timeout = socket_timeout\n@@ -70,8 +72,9 @@ def __init__(self, max_interval=None, app=None,\n             self.loglevel = LOG_LEVELS[self.loglevel.upper()]\n \n     def run(self):\n-        print(str(self.colored.cyan(\n-            f'celery beat v{VERSION_BANNER} is starting.')))\n+        if not self.quiet:\n+            print(str(self.colored.cyan(\n+                f'celery beat v{VERSION_BANNER} is starting.')))\n         self.init_loader()\n         self.set_process_title()\n         self.start_scheduler()\n@@ -93,7 +96,8 @@ def start_scheduler(self):\n             schedule_filename=self.schedule,\n         )\n \n-        print(self.banner(service))\n+        if not self.quiet:\n+            print(self.banner(service))\n \n         self.setup_logging()\n         if self.socket_timeout:\ndiff --git a/celery/bin/beat.py b/celery/bin/beat.py\nindex 9fcdc760794..c8a8a499b51 100644\n--- a/celery/bin/beat.py\n+++ b/celery/bin/beat.py\n@@ -62,7 +62,8 @@ def beat(ctx, detach=False, logfile=None, pidfile=None, uid=None,\n         maybe_drop_privileges(uid=uid, gid=gid)\n \n     beat = partial(app.Beat,\n-                   logfile=logfile, pidfile=pidfile, **kwargs)\n+                   logfile=logfile, pidfile=pidfile,\n+                   quiet=ctx.obj.quiet, **kwargs)\n \n     if detach:\n         with detached(logfile, pidfile, uid, gid, umask, workdir):\ndiff --git a/t/unit/bin/proj/scheduler.py b/t/unit/bin/proj/scheduler.py\nnew file mode 100644\nindex 00000000000..089b4e0eaf1\n--- /dev/null\n+++ b/t/unit/bin/proj/scheduler.py\n@@ -0,0 +1,6 @@\n+from celery.beat import Scheduler\n+\n+\n+class mScheduler(Scheduler):\n+    def tick(self):\n+        raise Exception\n",
        "test_patch": "diff --git a/t/unit/bin/test_beat.py b/t/unit/bin/test_beat.py\nnew file mode 100644\nindex 00000000000..cd401ee7620\n--- /dev/null\n+++ b/t/unit/bin/test_beat.py\n@@ -0,0 +1,34 @@\n+import pytest\n+from click.testing import CliRunner\n+\n+from celery.app.log import Logging\n+from celery.bin.celery import celery\n+\n+\n+@pytest.fixture(scope='session')\n+def use_celery_app_trap():\n+    return False\n+\n+\n+def test_cli(isolated_cli_runner: CliRunner):\n+    Logging._setup = True  # To avoid hitting the logging sanity checks\n+    res = isolated_cli_runner.invoke(\n+        celery,\n+        [\"-A\", \"t.unit.bin.proj.app\", \"beat\", \"-S\", \"t.unit.bin.proj.scheduler.mScheduler\"],\n+        catch_exceptions=True\n+    )\n+    assert res.exit_code == 1, (res, res.stdout)\n+    assert res.stdout.startswith(\"celery beat\")\n+    assert \"Configuration ->\" in res.stdout\n+\n+\n+def test_cli_quiet(isolated_cli_runner: CliRunner):\n+    Logging._setup = True  # To avoid hitting the logging sanity checks\n+    res = isolated_cli_runner.invoke(\n+        celery,\n+        [\"-A\", \"t.unit.bin.proj.app\", \"--quiet\", \"beat\", \"-S\", \"t.unit.bin.proj.scheduler.mScheduler\"],\n+        catch_exceptions=True\n+    )\n+    assert res.exit_code == 1, (res, res.stdout)\n+    assert not res.stdout.startswith(\"celery beat\")\n+    assert \"Configuration -> \" not in res.stdout\n",
        "problem_statement": "celery worker has --quiet to suppress banner output but celery beat does not\nSorry for leaving out the issue template but I believe this is fairly trivial and straight-forward.\n\nIn master, there is code to enable the suppressing of printing the banner when running `celery worker` with `--quiet`:\nhttps://github.com/celery/celery/blob/9773eba837982c84380c93bd3788470273e7674d/celery/apps/worker.py#L138-L139\n\nThis conditional is not present in the code that runs `celery beat`:\nhttps://github.com/celery/celery/blob/9773eba837982c84380c93bd3788470273e7674d/celery/apps/beat.py#L77-L78\nhttps://github.com/celery/celery/blob/9773eba837982c84380c93bd3788470273e7674d/celery/apps/beat.py#L100\n\nThis causes a few issues for us because we expect all our services to only emit JSON.\n\n\n",
        "hints_text": "do you have the time to send improvements?\nI do, with a little guidance. Do I just need to add the `quiet` kwarg to `on_before_init` in `beat.py`? Or is there something more I need to do to make sure that I can figure out whether `--quiet` was passed or not?\nping :)\n> I do, with a little guidance. Do I just need to add the `quiet` kwarg to `on_before_init` in `beat.py`? Or is there something more I need to do to make sure that I can figure out whether `--quiet` was passed or not?\r\n\r\nyou really need to dig the code to figure out that",
        "created_at": "2022-07-05T02:45:37Z",
        "version": "5.3",
        "PASS_TO_PASS": [],
        "FAIL_TO_PASS": []
    }
]